\begin{plSection}{Notation and general results}
\label{sec:general}
%-----------------------------------------------------------------
\begin{plSection}{Identities for real vector operations}
\label{sec:RX}

See \citeAuthorYearTitle[p. 85, ex. 4-9]{Spivak:1965:CalculusOnManifolds}.

Let $\Vector{p}, \Vector{q} \in \Reals^{n}$.
Let $\theta(\Vector{p},\Vector{q})$ be the angle between $\Vector{p}$ and $\Vector{q}$.

\begin{itemize}
\item The inner (dot) product:
\begin{equation}
\Vector{p} \bullet \Vector{q} \; \equiv \; \sum_{i=0}^{n-1} p_i q_i
\end{equation}

\item The euclidean ($l_2$) norm:
\begin{equation}
\| \Vector{p} \|^2 \; \equiv \; \Vector{p} \bullet \Vector{p}
\end{equation}
\begin{equation}
\Vector{p} \bullet \Vector{q} \; = \; \| \Vector{p} \| \| \Vector{q} \| \cos(\theta(\Vector{p},\Vector{q}))
\end{equation}

\item Orthogonal complement:
\begin{equation}
\Vector{p} \perp \Vector{q} 
\; \equiv \; \Vector{p} 
\; - \; 
\left( 
\Vector{p} \bullet 
\frac{\Vector{q}}{\|\Vector{q}\|}
\right) 
\end{equation}

\item The tensor product

Let $\Vector{p} \in \Reals^m, \Vector{q}, \Vector{r} \in \Reals^n.$
$\Vector{p} \otimes \Vector{q}$ is a rank 1 linear transformation
from $\Reals^n$ to $\Reals^m$, defined by:
\begin{equation}
(\Vector{p} \otimes \Vector{q})(\Vector{r}) \; \equiv \; \Vector{p} (\Vector{q} \bullet \Vector{r})
\end{equation}

\end{itemize}

\end{plSection}%{Identities for real vector operations}
%-----------------------------------------------------------------
\begin{plSection}{Identities for 3-dimensional vector operations}
\label{sec:R3X}

See \citeAuthorYearTitle[p. 85, ex. 4-9]{Spivak:1965:CalculusOnManifolds}.

Let $\Vector{p}, \Vector{q}, \Vector{r} \in \Reals^3$.
Let $(p_0,p_1,p_2), (q_0,q_1,q_2), (r_0,r_1,r_2), $ be their coordinates
in some orthonormal basis.

The cross product:
\begin{equation}
\Vector{p} \times \Vector{q}  
\; \equiv \; 
(p_1 q_2 - p_2 q_1, \; p_2 q_0 - p_0 q_2, \; p_0 q_1 - p_1 q_0)
\end{equation}
\begin{equation}
\Vector{p} \times \Vector{q}  
\; = \; - \; 
\Vector{q} \times \Vector{p}
\end{equation}
\begin{equation}
\| \Vector{p} \times \Vector{q} \| \; = \; \| \Vector{p} \| \;
 \| \Vector{q} \| \; \sin(\theta(\Vector{p},\Vector{q}))
\end{equation}
\begin{equation}
\| \Vector{p} \times \Vector{q} \|  
\; = \;  
\sqrt{\| \Vector{p} \|^2 \| \Vector{q} \|^2
 \; - \; (\Vector{p} \bullet \Vector{q})^2}
\end{equation}
\begin{equation}
\Vector{p} \bullet ( \Vector{p} \times \Vector{q} ) 
\; = \; ( \Vector{p} \times \Vector{q} ) \bullet \Vector{q} \; = \; 0
\end{equation}
\begin{equation}
\label{eq:dot_cross}
\Vector{p} \bullet ( \Vector{q} \times \Vector{r} ) 
\; = \; ( \Vector{p} \times \Vector{q} ) \bullet \Vector{r} 
\; = \; \Vector{q} \bullet ( \Vector{r} \times \Vector{p} )
\end{equation}
\begin{equation}
\Vector{p} \times ( \Vector{q} \times \Vector{r} )
 \; = \; 
 ( \Vector{p} \bullet \Vector{r} ) \Vector{q}
  \; - \; (\Vector{p} \bullet \Vector{q}) \Vector{r}
\end{equation}
\begin{equation}
( \Vector{p} \times \Vector{q} ) \times \Vector{r} 
\; = \; 
( \Vector{p} \bullet \Vector{r} ) \Vector{q} 
\; - \; (\Vector{q} \bullet \Vector{r}) \Vector{p}
\end{equation}
\begin{equation}
( \Vector{p} \times \Vector{q} ) \times \Vector{r} 
\; = \;
 \left((\Vector{q} \otimes \Vector{p})
  - (\Vector{p} \otimes \Vector{q})\right) \Vector{r}
\end{equation}

\end{plSection}%{Identities for 3-dimensional vector operations}
%-----------------------------------------------------------------
\begin{plSection}{Functions on real vector spaces}
\label{sec:functions}

This paper describes functions of triangular meshes.

Interesting functions usually depend, directly or indirectly,
on the positions of some subset of the vertices.
I consider the vertex positions to be elements of $\Reals^3$,
with an (implied) universal origin,
and thus do not distinguish points and vectors.

In general, the functions discussed here map between real vector spaces:
$\Vector{f}:{\Re}^{n} \mapsto \Reals^{m}$, where $\Reals^n$ is the
{\it domain} and $\Reals^m$ is the {\it codomain}.
Strictly speaking, the {\it range} of $\Vector{f}$ is the set $\Vector{f}(\Reals^n)$,
which may be a proper subset of its codomain $\Reals^m$.

I typically use $\Vector{p}$, $\Vector{q}$, $\Vector{r}$, etc., for elements of $\Reals^n$
and
$\Vector{f}$, $\Vector{g}$, $\Vector{h}$ for vector-valued functions.
I generally do not distinguish $\Re$, the real numbers,
and $\Reals^1$, the 1-dimensional real vector space.
I sometimes use $f$, $g$, $h$ for extra clarity in the special
case of real-valued functions.

The domains of many interesting functions,
such as those that depend on vertex positions,
are direct sums of $\Reals^3$.
The {\it direct sum} $\Reals^n \oplus \Reals^m$ is the cartesian product
of $\Reals^n$ and $\Reals^m$ --- the set of ordered pairs $(\Vector{p},\Vector{q})$
where $\Vector{p} \in \Reals^n$ and $\Vector{q} \in \Reals^m$ ---
with the restriction that the inner product is the obvious extension of the
inner products on $\Reals^n$ and $\Reals^m$:
$(\Vector{p}_0,\Vector{q}_0) \bullet (\Vector{p}_1,\Vector{q}_1) = (\Vector{p}_0 \bullet \Vector{p}_1) + (\Vector{q}_0 \bullet \Vector{q}_1).$
For simplicity, I identify
$\Reals^{3n} = \Reals^3 \oplus \Reals^3 \oplus \cdots \oplus \Reals^3 = \oplus^n \Reals^3
= \Reals^n \oplus \Reals^n \oplus \Reals^n $.
I will usually write an element of $\oplus^n \Reals^3$ as
$(\Vector{p}_0,\ldots,\Vector{p}_{n-1})$
and use
$\Vector{f}(\Vector{p}_0,\Vector{p}_1,\ldots,\Vector{p}_{n-1})$
for a function that depends on $n$ vertices.
Sometimes it will be useful to separate the $x,$ $y,$ and $z$ coordinates:
$\Vector{p} = (\Vector{x},\Vector{y},\Vector{z}),$
where $\Vector{x} =(x_0, \ldots x_{n-1}) \in \Reals^n$, are the $x$-coordinates
of the positions of the vertices, and similarly for $y$ and $z$.

\end{plSection}%{Functions on real vector spaces}
%-----------------------------------------------------------------
\begin{plSection}{Derivatives}
\label{sec:derivatives}

One way to view the derivative of a function
$\Vector{f}:{\Re}^{n} \mapsto \Reals^{m}$,
at a point $\Vector{p}$,
is as the linear transformation 
$\Vector{L}:{\Re}^{n} \mapsto \Reals^{m}$,
that best approximates the local 'slope' of 
$\Vector{f}$ at $\Vector{p}$.
To be a little more precise, we want
\begin{displaymath}
\lim_{ \|\deltaBold\| \mapsto 0}
\frac{\|
\Vector{f}(\Vector{p} + \deltaBold) 
- \left( \Vector{f}(\Vector{p}) + \Vector{L}(\deltaBold) \right) 
\|}
{\|\deltaBold\|}
 = 0
\end{displaymath}
For a concise and correct discussion, see \citeAuthorYearTitle{Spivak:1965:CalculusOnManifolds}.

\begin{itemize}

\item $\Derivative{\Vector{f}}$

In its most general form,
I denote the derivative of $\Vector{f}$ 
by $\Derivative{\Vector{f}}$.
Note that this is
linear-transformation-valued function 
of the domain of $\Vector{f}$.

\item $\Derivative{\Vector{f}}[\Vector{p}]$

I denote the derivative of $\Vector{f}$ 
at $\Vector{p}$ by $\Derivative{\Vector{f}}[\Vector{p}]$.
$\Derivative{\Vector{f}}[\Vector{p}]$ 
is a specific linear transformation from
the domain of $\Vector{f}$ to the codomain of $\Vector{f}$.

\item $\Derivative{\Vector{f}}[\Vector{p}][\Vector{q}]$

The derivative is most often represented by the {\it Jacobian},
the $m \times n$ matrix of partial derivatives
with respect to some bases for $\Reals^n$ and $\Reals^m$.
However, it's often easier to express the derivative clearly if we
explicitly include the argument of the linear transformation.
In this case, I write $\Derivative{\Vector{f}}[\Vector{p}][\Vector{q}]$
for the derivative of $f$ at the point $\Vector{p}$
applied to the vector $\Vector{q}$.

\item $\Derivative[\Vector{p}_i]
{\Vector{f}}
[(\Vector{q}_0,\ldots,\Vector{q}_{n-1})]
[\Vector{r}_i]$

For functions on direct sum spaces,
$\Vector{f}(\Vector{p}_0,\Vector{p}_1,\ldots,
\Vector{p}_{n-1})$, 
$\Vector{p}_i \in \Reals^{n_i}$,
it's often easier to consider the derivative
with respect to one argument at a time.
I write 
$\Derivative[\Vector{p}_i]
{\Vector{f}}
[(\Vector{q}_0,\ldots,\Vector{q}_{n-1})]
[\Vector{r}_0,\ldots,\Vector{r}_{n-1}]$
for the derivative of $\Vector{f}$ 
with respect to $\Vector{p}_i$,
at the point 
$(\Vector{q}_0,\ldots,\Vector{q}_{n-1})
 \in \oplus_{i=0}^{n-1} \Reals^{m_i}$,
applied to the vector $\Vector{r}_i \in \Reals^{n_i}$.
Note that, if you consider $\Vector{f}$ to be a function
of direct sums of $\Reals^1$, we have the usual
partial derivatives.

\end{itemize}

%-----------------------------------------------------------------
\begin{plSection}{Gradients of real-valued functions}
\label{sec:gradients}

\begin{itemize}

\item $\Gradient{f}$

In minimizing real-valued functions, $f(\Vector{p})$, $\Vector{p} \in \Reals^n$,
we frequently need
the {\it gradient,} $\Gradient{f} \in \Reals^n$,
the vector pointing in the direction of most rapid increase of $f$,
whose magnitude is the rate of increase, or slope,
of $f$ in that direction.

The gradient, $\Gradient{f}$,
has a close relationship to the derivative, $\Derivative{f}$,
and the two are often confused.
Recall that the derivative is a linear transformation
from the domain of $f$ to its codomain.
In the case of real-valued functions,
this means the derivative is a linear function on $\Reals^n$,
an element of the dual space of $\Reals^n$, a 'row' vector.
It's easy to see that the gradient is simply the dual (the 'transpose')
of the derivative, $\Gradient{f} = (\Derivative{f})^{\dagger}$
(see \citeAuthorYearTitle[p. 96, ex. 4-18]{Spivak:1965:CalculusOnManifolds}).

Notation for the various versions of the gradient
follows that for derivatives:

\item $\Gradient{f}[\Vector{q}]$

The gradient of $f$ at $\Vector{q}$.

\item $\Gradient[\Vector{p}_i]{f}[\Vector{q}]$

The gradient of $f$
with respect to $\Vector{p}_i$ at $\Vector{q}$.

\item $(\Gradient{f}[\Vector{q}]) \bullet \; \Vector{r}$

The analog to expressing the derivative as a linear transformation
with an explicit argument is to write expressions for
the inner product of the gradient and an arbitrary other vector 
$\Vector{r}$

\item $(\Gradient[\Vector{p}_i]{f}[\Vector{q}]) \bullet \;\Vector{r}_i$

See above.

\end{itemize}

\end{plSection}%{Gradients of real-valued functions}
%-----------------------------------------------------------------
\begin{plSection}{Chain rule}
\label{sec:chain}

The most general identity used in computing derivatives i
s the {\it chain rule.}
Suppose
$\Vector{f}:\Reals^{n_0} \mapsto \Reals^{n_1}$,
$\Vector{g}:\Reals^{n_1} \mapsto \Reals^{n_2}$,
and
$\Vector{h} =
 \Vector{g} \circ \Vector{f} 
 : \Reals^{n_0} \mapsto \Reals^{n_2}.$
Then
\begin{equation}
\label{eq:chain-rule}
\Derivative{\Vector{h}}[\Vector{u}]
=  \Derivative{(\Vector{g} \circ \Vector{f})}[\Vector{v}]
=  \Derivative{\Vector{g}}[\Vector{f}(\Vector{v})]
  \circ  \Derivative{\Vector{f}}[\Vector{v}].
\end{equation}

See \citeAuthorYearTitle[Theorem~2-2]{Spivak:1965:CalculusOnManifolds}, .

\end{plSection}%{Chain rule}
%-----------------------------------------------------------------
\begin{plSection}{Derivatives of multilinear functions}
\label{sec:multilinear}

A function 
$\Vector{f}(\Vector{p}_0,\ldots,\Vector{p}_k) 
: \Reals^{n_0} \oplus \Reals^{n_k} \mapsto \Reals^m$
is {\it multilinear} if
\begin{equation}
\Vector{f}(
a_{00} \Vector{p}_{00} + a_{01} \Vector{p}_{01}, 
\ldots, 
a_{k0} \Vector{p}_{k0} + a_{k1} \Vector{p}_{k1})
\; = \; 
\sum_{i_0,\ldots,i_k = 0,1} \;
(a_{0i_0} \cdots a_{ki_k}) 
\Vector{f}(\Vector{p}_{0i_0}, \ldots, \Vector{p}_{ki_k}).
\end{equation}

The derivative of $\Vector{f}$
at the point $(\Vector{p}_0,\ldots,\Vector{p}_k)$, 
applied to the vector $(\Vector{q}_0,\ldots,\Vector{q}_k)$ is

\begin{equation}
\Derivative{\Vector{f}}
[(\Vector{p}_0,\ldots,\Vector{p}_k)]
[\Vector{q}_0,\ldots,\Vector{q}_k]
\; = \; 
\sum_{i=0,k} 
\Vector{f}(
\Vector{p}_0,
\ldots,
\Vector{p}_{i-1},
\Vector{q}_i,
\Vector{p}_{i+1},
\ldots,
\Vector{p}_k).
\end{equation}

See \citeAuthorYearTitle[ex.~2-14]{Spivak:1965:CalculusOnManifolds}, .

\end{plSection}%{Derivatives of multilinear functions}
%-----------------------------------------------------------------
\begin{plSection}{Derivatives of bilinear functions}
\label{sec:bilinear}

Bilinear functions are a useful special case 
of multilinear functions.

A function 
$\Vector{f}(\Vector{p},\Vector{q}) :
\Reals^{n_0} \oplus \Reals^{n_1} \mapsto \Reals^m$
is {\it bilinear} if
\begin{eqnarray}
\Vector{f}(
a_0 \Vector{p}_0 + a_1 \Vector{p}_1, 
b_0 \Vector{q}_0 + b_1 \Vector{q}_1) 
& = & a_0 b_0 f(\Vector{p}_0,\Vector{q}_0)  \\
& + & a_0 b_1 f(\Vector{p}_0,\Vector{q}_1) \nonumber \\
& + & a_1 b_0 f(\Vector{p}_1,\Vector{q}_0) \nonumber \\
& + & a_1 b_1 f(\Vector{p}_1,\Vector{q}_1).\nonumber
\end{eqnarray}

The derivative of $\Vector{f}$
at the point $(\Vector{p}_0,\Vector{q}_0)$, 
applied to the vector $(\Vector{p},\Vector{q})$ is

\begin{equation}
\Derivative{\Vector{f}}
[(\Vector{p}_0,\Vector{q}_0)]
[\Vector{p},\Vector{q}]
 = \Vector{f}(\Vector{p}_0,\Vector{q})
 + \Vector{f}(\Vector{p},\Vector{q}_0).
\end{equation}

See \citeAuthorYearTitle[ex.~2-12]{Spivak:1965:CalculusOnManifolds}.

\end{plSection}%{Derivatives of bilinear functions}
%-----------------------------------------------------------------
\begin{plSection}{Derivatives of linear functions}
\label{sec:Derivatives-of-linear-functions}

Linear functions are another useful special case of multilinear functions.
A function $\Vector{f}(\Vector{p}):\Reals^{n} \mapsto \Reals^m$
is {\it linear} if
\begin{equation}
\Vector{f}(a_0 \Vector{p}_0 + a_1 \Vector{p}_1)
 =
a_0 \Vector{f}(\Vector{p}_0) + a_1 \Vector{f}(\Vector{p}_1)
\end{equation}

The derivative of $\Vector{f}$ is simply $\Vector{f}$ itself.

\end{plSection}%{Derivatives of linear functions}
%-----------------------------------------------------------------
\begin{plSection}{Derivatives of inner products}
\label{sec:inner}

We can view the inner product on $\Reals^m$, $\Vector{p} \bullet \Vector{q}$,
as a bilinear function $d(\Vector{p},\Vector{q}) : \Reals^m \oplus \Reals^m \mapsto \Re$.
Thus
\begin{equation}
\Derivative{d}[(\Vector{p}_0,\Vector{q}_0)][\Vector{p},\Vector{q}]
 = \Vector{p}_0 \bullet \Vector{q} + \Vector{p} \bullet \Vector{q}_0.
\end{equation}

Suppose
$\Vector{f}:\Reals^{n} \mapsto \Reals^{m}$, and
$\Vector{g}:\Reals^{n} \mapsto \Reals^{m}$.
The derivative of $\Vector{f} \bullet \Vector{g}$ is:
\begin{eqnarray}
\label{eq:dot_derivative}
\Derivative{(\Vector{f} \bullet \Vector{g})}[\Vector{p}_0][\Vector{p}]
& =
& \Derivative{d}[(\Vector{f}(\Vector{p}_0),\Vector{g}(\Vector{p}_0))]
 \;\circ \;
 (\Derivative{\Vector{f}}[\Vector{p}_0][\Vector{p}], 
 \Derivative{\Vector{g}}[\Vector{p}_0][\Vector{p}])
\\
& =
& \Vector{f}(\Vector{p}_0) \bullet 
\Derivative{\Vector{g}}[\Vector{p}_0][\Vector{p}] 
\; + \; \Vector{g}(\Vector{p}_0) 
\bullet \Derivative{\Vector{f}}[\Vector{p}_0][\Vector{p}] \nonumber
\end{eqnarray}

See \citeAuthorYearTitle[ex.~2-13]{Spivak:1965:CalculusOnManifolds}.

\end{plSection}%{Derivatives of inner products}
%-----------------------------------------------------------------
\begin{plSection}{Derivatives of cross products}
\label{sec:cross}

We can view the 3-dimensional cross product
$ \times $
as a bilinear function
$\Vector{c}(\Vector{p},\Vector{q}) = 
\Vector{p} \times \Vector{q}
 : \Reals^3 \oplus \Reals^3 \mapsto \Reals^3$.
As with the inner product,
the derivative is
\begin{equation}
\Derivative{c}
[(\Vector{p}_0,\Vector{q}_0)]
[\Vector{p},\Vector{q}] 
= \Vector{p}_0 \times \Vector{q} 
+ \Vector{p} \times \Vector{q}_0.
\end{equation}

Suppose
$\Vector{f}:\Reals^{n} \mapsto \Reals^3$, and
$\Vector{g}:\Reals^{n} \mapsto \Reals^3$.
The derivative of $\Vector{f} \times \Vector{g}$ is:
\begin{eqnarray}
\Derivative{(\Vector{f} \times \Vector{g})}
[\Vector{p}_0][\Vector{p}]
& =
& \Derivative{\Vector{c}}
[(\Vector{f}(\Vector{p}_0),\Vector{g}(\Vector{p}_0))]
\;\circ \;
(\Derivative{\Vector{f}}[\Vector{p}_0][\Vector{p}],
 \Derivative{\Vector{g}}[\Vector{p}_0][\Vector{p}])
\\
& =
& \Vector{f}(\Vector{p}_0) 
\;\times \;
\Derivative{\Vector{g}}[\Vector{p}_0][\Vector{p}] 
\;+ \;
\Derivative{\Vector{f}}[\Vector{p}_0][\Vector{p}] 
\;\times \;
\Vector{g}(\Vector{p}_0) \nonumber
\end{eqnarray}

\end{plSection}%{Derivatives of cross products}
%-----------------------------------------------------------------
\begin{plSection}{Derivatives of scalar products}
\label{sec:scalar}

Suppose
$f:\Reals^{n} \mapsto \Re$, and
$\Vector{g}:\Reals^{n} \mapsto \Reals^m$.
It follows from the chain rule that the derivative of 
$\Vector{h} = f\Vector{g}$ is:
\begin{eqnarray}
\label{eq:scalar_product_derivative}
\Derivative{(f\Vector{g})}[\Vector{p}]
& = & f(\Vector{p})
\;\Derivative{\Vector{g}}[\Vector{p}] 
\;+ \Vector{g}(\Vector{p}) \; 
\Derivative{f}[\Vector{p}]  \\
& = & f(\Vector{p}) \;
\Derivative{\Vector{g}}[\Vector{p}] 
\;+ \Vector{g}(\Vector{p}) 
\otimes 
\Gradient{f}[\Vector{p}] \; \nonumber
\end{eqnarray}

\end{plSection}%{Derivatives of scalar products}
%-----------------------------------------------------------------
\begin{plSection}{Derivatives of euclidean norms}
\label{sec:norms}

Let $l_2(\Vector{p}) = \; \| \Vector{p}  \|
: \Reals^n \mapsto \Reals$ 
be the usual euclidean norm on $\Reals^n$.
Let $l_2^2(\Vector{p}) = \; \| \Vector{p}  \|^2 $
be its square
($ \| \Vector{p}  \|^2  = \sum_{i=0,n-1} \Vector{p}_i^2$),
and $ \| \Vector{p}  \|^3$ the cube.
\begin{eqnarray}
\label{eq:l2-gradient}
\Gradient{l_2}[\Vector{p}] 
& = & \frac{\Vector{p}}{\|\Vector{p}\|} \\
\Derivative{l_2}[\Vector{p}]
 & = & \frac{ \Vector{p}^\dagger }{ \|\Vector{p}\|} \nonumber \\
\Gradient{l_2^2}[\Vector{p}] & = & 2\Vector{p} \nonumber \\ 
\Derivative{l_2^2}[\Vector{p}] & = & 2\Vector{p}^\dagger \nonumber \\
\Gradient{l_2^3}[\Vector{p}] 
& = & 3 \| \Vector{p}  \| \Vector{p} \nonumber \\
\Derivative{l_2^3}[\Vector{p}] 
& = & 3 \| \Vector{p}  \| \Vector{p}^\dagger \nonumber
\end{eqnarray}

Let $\Vector{f}(\Vector{p}) : \Reals^n \mapsto \Reals^m$.
By the chain rule:
$\Derivative{\| \Vector{f} \|^2}[\Vector{p}]
=  
2 {\Vector{f}(\Vector{p})}^{\dagger}
 \Derivative{\Vector{f}}[\Vector{p}] $.

\begin{equation}
\Gradient{\| \Vector{f} \|^2}[\Vector{p}]  = 
 2 \;\Derivative{\Vector{f}}[\Vector{p}]^\dagger 
 \;\circ \;\Vector{f}(\Vector{p})
\end{equation}

\begin{eqnarray}
\label{eq:norm_derivative}
\Derivative{\| \Vector{f} \|}[\Vector{p}]
& = &
\frac{\Vector{f}(\Vector{p})^\dagger} 
{\| \Vector{f}(\Vector{p}) \|} 
\Derivative{\Vector{f}}[\Vector{p}]  \\
\Gradient{\| \Vector{f} \|}[\Vector{p}]
& = &
\left(\Derivative{\Vector{f}}[\Vector{p}]\right)^\dagger
\;\circ \;
\frac{\Vector{f}(\Vector{p})} 
{\|\Vector{f}(\Vector{p})\|}
\label{eq:norm_gradient}
\end{eqnarray}

\end{plSection}%{Derivatives of euclidean norms}
%-----------------------------------------------------------------
\begin{plSection}{Derivatives of normalized functions}
\label{sec:Derivatives-of-normalized-functions}

Let $\tilde{\Vector{f}}$ be the normalized version of 
$\Vector{f}$:
\begin{equation}
\tilde{\Vector{f}} \;= \;
\frac{\Vector{f}}{\|\Vector{f}\|}
\end{equation}

Then, from \cref{eq:scalar_product_derivative}
and \cref{eq:norm_derivative}:
\begin{eqnarray}
\Derivative{\tilde{\Vector{f}}}[\Vector{p}][\Vector{q}]
& = &
\Derivative
{\left(\frac{\Vector{f}}{\|\Vector{f}\|}\right)}
[\Vector{p}]
[\Vector{q}]
\\
& = &
\frac{\Derivative{\Vector{f}}[\Vector{p}][\Vector{q}]}
{\|\Vector{f}(\Vector{p})\|}
\; + \;
\Vector{f}(\Vector{p}) \; 
\Derivative
{\left[\frac{1}{\|\Vector{f}\|}\right]}
[\Vector{p}]
[\Vector{q}] \nonumber \\
& = &
\frac{\Derivative{\Vector{f}}[\Vector{p}][\Vector{q}]} 
{\| \Vector{f}(\Vector{p}) \|}
\; - \;
\Vector{f}(\Vector{p}) 
\frac{\Derivative{\| \Vector{f} \|}[\Vector{p}][\Vector{q}]}
{\|\Vector{f}(\Vector{p})\|^2} \nonumber \\
& = &
\frac{\Derivative{\Vector{f}}[\Vector{p}][\Vector{q}]}
{\|\Vector{f}(\Vector{p})\|}
\; - \;
\Vector{f}(\Vector{p})
\left( 
\frac{\Vector{f}(\Vector{p})^\dagger} 
{\|\Vector{f}(\Vector{p})\|^3} 
\;
\Derivative{\Vector{f}}[\Vector{p}][\Vector{q}] 
\right) \nonumber \\
& = &
\frac{
\| \Vector{f}(\Vector{p}) \|^2 
\Derivative{\Vector{f}}[\Vector{p}][\Vector{q}]
\; - \;
\Vector{f}(\Vector{p})
\left( 
\Vector{f}(\Vector{p}) 
\bullet 
\Derivative{\Vector{f}}[\Vector{p}][\Vector{q}] \right) 
}
{\| \Vector{f}(\Vector{p}) \|^3}  
\nonumber \\
& = &
\frac{
\| \Vector{f}(\Vector{p}) \|^2 
\Identity_{\Reals^3} 
\;- \;
\left( 
\Vector{f}(\Vector{p})
\otimes 
\Vector{f}(\Vector{p}) 
\right) 
}
{\| \Vector{f}(\Vector{p}) \|^3} 
\;
\Derivative{\Vector{f}}[\Vector{p}][\Vector{q}] 
\nonumber \\
& = &
\frac{
\Identity_{\Reals^3} 
\;- \;
\left( 
\tilde{\Vector{f}}(\Vector{p})
\otimes 
\tilde{\Vector{f}}(\Vector{p}) 
\right)  
}
{\| \Vector{f}(\Vector{p}) \|} 
\;\Derivative{\Vector{f}}[\Vector{p}][\Vector{q}] \nonumber
\end{eqnarray}

where $\otimes$ is the elementary tensor product operation.
If you are stuck thinking in terms of row and column vectors,
$\Vector{p} \otimes \Vector{q} \;= \;\Vector{p}\Vector{q}^\dagger$.
More generally, if $\Vector{p} \in \Reals^m$ and $\Vector{q} \in \Reals^n$,
then $\Vector{p} \otimes \Vector{q}$ 
is the rank 1 linear transformation from
 $\Reals^n \mapsto \Reals^m$:
$\left(\Vector{p} \otimes \Vector{q}\right) 
(\Vector{r}) \;= \;\Vector{p} \left(\Vector{q} \bullet \Vector{r}\right)$.

We can write the derivative above without reference 
to the argument $\Vector{q}$:
\begin{eqnarray}
\label{eq:normalized_function_derivative}
\Derivative{\tilde{\Vector{f}}}[\Vector{p}]
& = &
\Derivative
{\left[
\frac{\Vector{f}}{\|\Vector{f}\|}
\right]}
[\Vector{p}] \\
& = &
\frac{
\Identity_{\Reals^3} 
\;- \;
\left[
\tilde{\Vector{f}}(\Vector{p})
\otimes 
\tilde{\Vector{f}}(\Vector{p}) 
\right]
}
{\|\Vector{f}(\Vector{p})\|} 
\;
\Derivative{\Vector{f}}[\Vector{p}] \nonumber
\end{eqnarray}

A common, trivial, normalized function is the normalized version of
a vector:
\begin{equation}
\tilde{\Vector{p}} \;= \; \frac{\Vector{p}}{\|\Vector{p}\|}
\end{equation}

From equation \cref{eq:normalized_function_derivative}
it follows that:
\begin{eqnarray}
\label{eq:normalized_vector_derivative}
\Derivative{\tilde{\Vector{p}}}[\Vector{q}]
& = &
\Derivative
{\left(
\frac{\Vector{p}}{\|\Vector{p}\|}
\right)}
[\Vector{q}]
\\
& = &
\frac{
\Identity_{\Reals^3} 
\;- \;
\left( \tilde{\Vector{q}} \otimes \tilde{\Vector{q}} \right)
}
{\| \Vector{q} \|}
\nonumber
\\
& = &
\frac{
\|\Vector{q}\|^2
 \Identity_{\Reals^3} 
 \;- \;
 \left( \Vector{q} \otimes \Vector{q} \right) 
 }
{\| \Vector{q} \|^3} 
\nonumber
\end{eqnarray}

\end{plSection}%{Derivatives of normalized functions}
%-----------------------------------------------------------------
\begin{plSection}{Derivatives of angles}
\label{sec:derivatives-of-angles}

The angle between 2 vectors 
$\Vector{p}_0, \Vector{p}_1 \in \Reals^m$, 
is the inverse cosine
of their normalized inner product:
\begin{equation}
\theta(\Vector{p}_0,\Vector{p}_1)
=
\cos^{-1}
\left(
\frac{ \Vector{p}_0 \bullet \Vector{p}_1 } 
{\|\Vector{p}_0\| \|\Vector{p}_1\|}
\right)
\end{equation}
Recall that the derivative of the $\cos^{-1}$ is:
\begin{equation}
\frac{\mathit d}{\mathit dx} 
\cos^{-1}(x) 
= 
\frac{-1}{\sqrt{1-x^2}} 
\end{equation}
It follows that:
\begin{eqnarray}
\label{eq:angle_gradient}
\Gradient[\Vector{p}_0]{\theta(\Vector{p}_0,\Vector{p}_1)}[\Vector{q}]
& = &
\frac{-1}
{
\sqrt{1-
\left(
\frac{\Vector{q}_0 \bullet \Vector{q}_1} 
{\| \Vector{q}_0 \| \| \Vector{q}_1 \|}
\right)^2}
}
\Gradient[\Vector{p}_0]
{\left( 
\frac{\Vector{q}_0 \bullet \Vector{q}_1} 
{\| \Vector{q}_0 \| \| \Vector{q}_1 \|} 
\right)}
[\Vector{q}]
\\
& = &
\frac{-\|\Vector{q}_0\|\|\Vector{q}_1\|}
{ 
\sqrt{\|\Vector{q}_0\|^2\|\Vector{q}_1\|^2 
- \left( \Vector{q}_0 \bullet \Vector{q}_1 \right)^2 }
}
\left[
\frac{\Vector{q}_1}{\|\Vector{q}_0\|\|\Vector{q}_1\|}
+
\frac{
\left( 
\Vector{q}_0 \bullet \Vector{q}_1 
\right)
} 
{\| \Vector{q}1 \|}
\Gradient[\Vector{p}_0]
{\left(\frac{1}{\| \Vector{p}_0 \|} \right)} 
[\Vector{q}]
\right]
\nonumber
\\
& = &
\frac{-\|\Vector{q}_0\|\|\Vector{q}_1\|}
{ 
\sqrt{
\|\Vector{q}_0\|^2\|\Vector{q}_1\|^2 
\,-\,
\left( \Vector{q}_0 \bullet \Vector{q}_1 \right)^2 
}
}
\left[
\frac{\Vector{q}_1}{\|\Vector{q}_0\|\|\Vector{q}_1\|}
-
\frac{\left( \Vector{q}_0 \bullet \Vector{q}_1 \right) \Vector{q}_0} 
{\| \Vector{q}_1 \| \|\Vector{q}_0\|^3}
\right]
\nonumber
\\
& = &
\frac{-1}
{ 
\sqrt{
\|\Vector{q}_0\|^2\|\Vector{q}_1\|^2 
\,-\,
\left( \Vector{q}_0 \bullet \Vector{q}_1 \right)^2 
}
}
\left[
\Vector{q}_1
-
\frac{\left( \Vector{q}_0 \bullet \Vector{q}_1 \right) \Vector{q}0} 
{\|\Vector{q}_0\|^2}
\right]
\nonumber
\\
& = &
\frac{-\Vector{q}_1 \perp \Vector{q}_0}
{ \sqrt{
\|\Vector{q}_0\|^2\|\Vector{q}_1\|^2
 - \left( \Vector{q}_0 \bullet \Vector{q}_1 \right)^2 
 }
 }
\nonumber
\\
&  &
\nonumber
\\
\Gradient[\Vector{p}_1]{\theta(\Vector{p}_0,\Vector{p}_1)}[\Vector{q}]
& = &
\frac{- \Vector{q}_0 \perp \Vector{q}_1}
{ \sqrt{\|\Vector{q}_0\|^2\|\Vector{q}_1\|^2 
- \left( \Vector{q}_0 \bullet \Vector{q}_1 \right)^2 }}
\nonumber
\end{eqnarray}
\end{plSection}%{Derivatives of angles}
%-----------------------------------------------------------------
\end{plSection}%{Derivatives}
%-----------------------------------------------------------------
\end{plSection}%{Notation and general results}
