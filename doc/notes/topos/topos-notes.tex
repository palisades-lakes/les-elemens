% !TEX TS-program = arara
% arara: xelatex: { synctex: on, options: [--halt-on-error] } 
% arara: biber
% arara: makeglossaries
% arara: makeindex
% arara: xelatex: { synctex: on, options: [-halt-on-error] } 
% arara: xelatex: { synctex: on, options: [-halt-on-error] } 
%%       arara: clean: { files: [topos-notes.aux,topos-notes.bbl] }
% arara: clean: { files: [topos-notes.bcf,topos-notes.blg] }
% arara: clean: { files: [topos-notes.glg,topos-notes.glo] }
% arara: clean: { files: [topos-notes.gls,topos-notes.gls] }
% arara: clean: { files: [topos-notes.idx,topos-notes.ilg] }
% arara: clean: { files: [topos-notes.ind,topos-notes.loe] }
% arara: clean: { files: [topos-notes.lof,topos-notes.log] }
% arara: clean: { files: [topos-notes.log,topos-notes.lol] }
% arara: clean: { files: [topos-notes.out,topos-notes.thm] }
% arara: clean: { files: [topos-notes.run.xml] }
% arara: clean: { files: [topos-notes.toc,topos-notes.xdy] }
% arara: clean: { files: [topos-notes.synctex.gz] }
%-------------------------------------------------------------------------------
\documentclass[11pt,openany]{article}
\usepackage{import}
\def \texFolder {../../tex/}
\def \bibFolder {../../bib/}
\def \sharedFolder {../../shared/}
\import{\texFolder}{head}
\import{\texFolder}{landscape-2col-8x17}
\import{\texFolder}{clj-listings}
\import{\sharedFolder}{glossary}
\addbibresource{{\bibFolder}algebra.bib}
\addbibresource{{\bibFolder}arithmetic.bib}
\addbibresource{{\bibFolder}cactus.bib}
\addbibresource{{\bibFolder}proglang.bib}
\addbibresource{{\bibFolder}halmos.bib}
\addbibresource{{\bibFolder}interpolation.bib}
\addbibresource{{\bibFolder}logic.bib}
\addbibresource{{\bibFolder}math.bib}
\addbibresource{{\bibFolder}mcdonald.bib}
\addbibresource{{\bibFolder}mop.bib}
\addbibresource{{\bibFolder}numbers.bib}
\addbibresource{{\bibFolder}sets.bib}
\addbibresource{{\bibFolder}tex.bib}
\addbibresource{{\bibFolder}topos.bib}
\addbibresource{{\bibFolder}feferman.bib}
%\addbibresource{{\bibFolder}ieeestd.bib}
%\addbibresource{{\bibFolder}fp.bib}
%-----------------------------------------------------------------
\title{Notes on category \\ and topos theory}
\author{\textsc{John Alan McDonald}}
%\email{mcdonald.john.alan at gmail.com}
\date{draft of \today}
%-----------------------------------------------------------------
\begin{document}

\maketitle

%-----------------------------------------------------------------
% 7 for part level
% 6 for chapter level
% 5 for section level
% 4 for subsection level
% 3 for subsubsection level
% 2 for paragraph level
% 1 for subparagraph level
\setcounter{baseSectionLevel}{5}
%-----------------------------------------------------------------

%\frontmatter

% \begingroup
% \let\onecolumn\twocolumn
% \sffamily
% \tableofcontents
% \rmfamily
% \endgroup
% 
%-----------------------------------------------------------------
\epigraph{
das Wesen der Mathematik liegt gerade in ihrer Freiheit.
\par
(The essence of mathematics lies precisely in its freedom.)}%
{Cantor~\cite{Cantor1883},
as quoted in~\cite{ferreiros2007labyrinth}.}

\epigraph{
Mathematics is not the rigid and petrifying schema, 
as the layman so much likes to view it; with it,
 we rather stand precisely at the point of intersection 
 of restraint and freedom that makes up the essence of man itself.}
{Weyl, 
\textit{Die heutige Erkenntnislage in der Mathematik}~\cite{weyl1926heutige};
translation from Mancosu~\cite{mancosu1998brouwer}.}

\epigraph{Mathematics as we practice it is much more formally 
complete and precise than
other sciences, but it is much less formally complete and precise 
for its content than computer programs.}%
{Thurston, 
\textit{On proof and progress in mathematics
}~\cite{thurston1994proof}}

\pagebreak
\epigraph{No doubt there are as many reasons for writing books as there are people
who write them. One function served by this particular work has been the
edification of its author. Translations can sometimes create a sense of
explanation, and this seemed to me particularly true of the alternative
account of mathematical constructions being produced by category
theory. Writing the book gave me a framework within which to confirm
that impression and to work through its ramifications in some detail. At
the end I knew a great deal more than when I began, so that the result is
as much a recording as a reconstruction of the progress of my own
understanding. And at the end it seemed to me that much that I had
dwelt on had finally fallen into place.
\par
As to the more public functions of the book - I hope that it provides
others with the prospect of a similar experience. Less presumptuously, I
have tried to write an exposition that will be accessible to the widest
possible audience of logicians - the philosophically motivated as well as
the mathematical. This, in part, accounts for the style that I have adopted.
There is a tendency in much contemporary literature to present material
in a highly systematised fashion, in which an abstract definition will
typically come before the list of examples that reveals the original
motivation for that definition. Paedogogically, a disadvantage of this
approach is that the student is not actually shown the genesis of concepts -
how and why they evolved-and is thereby taught nothing about the
mechanisms of creative thinking. Apart from lending the topic an often
illusory impression of completedness, the method also has the drawback
of inflating prerequisites to understanding.
\par
All of this seems to me particularly dangerous in the case of category
theory, a discipline that has more than once been referred to as ``abstract
nonsense''. In my experience, that reaction is the result of features that
are not intrinsic to the subject itself, but are due merely to the style of
some of its expositors. The approach I have taken here is to try to move
always from the particular to the general, following through the steps of
the abstraction process until the abstract concept emerges naturally. The
starting points are elementary (in the ``first principles'' sense), and at the
finish it would be quite appropriate for the reader to feel that (s)he had
just arrived at the subject, rather than reached the end of the story.}
{Goldblatt, \textit{Topoi, Preface}~\cite{goldblatt-1984-topoi}}
%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}}
\levelstay{Preface 2020-08}
\label{sec:Preface-2020-08}

Capture state of my ignorance as of 2020-08,
to record what's confusing to the novice.

For the past $20+$ years, I have, every year or so,
encountered claims that
category theory is the ``right way to do \textit{blah}''.
I would then pick up some recent 
introduction~\cite{adamek-herrlich-strecker-1990,
asperti-longo-1991,awodey-2010,
barr_wells_2020,
geroch-1985,hillman2001primer,lawvere-schanuel-2009,
leinster-2016-basic-category-theory,
maclane-1998-working-mathematician,nLab-2020,
riehl2017,
spivakd2013,spivakd2014} 
get about halfway and give up.

Recent context: 
writing optimization software 
leads to a desire for exact arithmetic 
leads to computable reals,
leads to constructive analysis and intuitionistic logic,
leads to history and foundations of math 
leads to topos theory.

Current hypothesis: something is wrong.
Maybe it's me, or maybe \ldots 
Directed multigraph perhaps isn't the 'right' language to
expose and use commonalities across mathematics.

\textbf{TODO:} is there a reasonable way to measure 
the complexity of a topic/definition/theorem/textbook,
something perhaps like the depth and branching of the
dependency tree? Are software complexity metrics a place to start?

Guess: right foundation should be self defining
(like any decent programming language).

motivation from empirical problems; 
see eg~\cite{maclane1981mathModels}.
goal ``breadth, clarity, and depth''.

my point of view: 
mathematics (notation) and programming languages
as \textit{written} languages,
used to formulate real world problems,
and construct their solutions.
express an idea in at most a couple pages of text.
say enough and not too much, especially not irrelevant things.
abstract just enough; 
concrete details of model/representation/implementation.

key issue: is the solution correct?
mathematics evaluated by consensus;
software by testing.

My background: physics undergraduate, statistics PhD.
A moderate amount of analysis; 
a bit of geometry, both
differential in the context of gravitation, and
discrete/computational in the context of fitting surfaces to
$3+$ data, and geospatial data analysis;
and a tiny amount of algebra, mostly group representations
for physics.

Three formative experiences:
\begin{enumerate}
  \item First day of my $4$-year high school (September $1967$):
  \par
  Our pre-calculus (?) math teacher, who was working on Math PhD,
  spent the first class on a (probably Bourbakian inspired) tour 
  of algebraic structures, groups, rings, fields, etc.
  I remember being fascinated, but distracted for much of the hour, 
  trying to figure out what was 'round' about rings.
  Despite my distraction, and almost total ignorance, 
  I remember it seeming like a natural exploration of the obvious
  possibilities from a simple starting point: a set of something,
  one or two binary operations, and likely properties those
  operations might or might not have.
 
  \item First semester freshman ($1$st) year of college,
  (Fall $1971$):
  \par
  Freshman math classes came in two versions: 
  general (primarily pre-med and engineering) audience
  vs intended math and physics majors. Fall semester was linear 
  algebra. Despite being in the math/physics version of the course,
  our text book was an introduction to matrix algebra of the type
  normally given to engineers, ie, unmotivated, complicated,
  arbitrary-seeming operations on rectangular arrays of numbers.
  I was lost. I remember being particularly put off by the 
  discussion of minors and determinants, a mysterious, 
  out-of-the-blue calculation used in solving systems in linear
  equations.
  \par
  Fortunately, our instructor recommended Halmos,
  \textsf{Finite dimensional vector 
  spaces}~\cite{Halmos1958Finite}. 
  
  \item Junior ($3$rd) year of college 
  (fall $1973$ -- spring $1974$):
  \par
  As physics majors, we took year-long courses in 
  electricity and magnetism, and quantum mechanics.
  Physics majors would also typically take math classes in
  ordinary differential equations, partial differential equations,
  real analysis, etc. We also mostly took a joint math/physics
  class called something like ``methods of modern mathematical 
  physics''~\cite{ReedSimon1972FunctionalAnalysis}, 
  which, as taught, was essentially a high-speed,
  more-or-less from scratch functional analysis course.
  Within the first month or so, we basically dispensed with all
  all the other courses we were taking special cases of 
  eigenanalysis of differential operators on function spaces.
  (also E+M Maxwell equations special case of Stokes theorem 
  from freshman Spivak Calculus on Manifolds.).
  
\end{enumerate}

\epigraph{Throughout these courses the infusion of a geometrical
point of view is of paramount importance. A vector
is geometrical; it is an element of a vector space, defined
by suitable axioms—whether the scalars be real numbers or
elements of a general field. A vector is not an n-tuple of
numbers until a coordinate system has been chosen. Any
teacher and any text book which starts with the idea that vectors
are n-tuples is committing a crime for which the proper
punishment is ridicule. The n-tuple idea is not ‘easier,’ it is
harder; it is not clearer, it is more misleading. By the same
token, linear transformations are basic and matrices are their
representations\ldots}
{MacLane, \textit{Of course and courses}~\cite{MacLane:1954}}

The common theme: the right abstraction reduces 
the amount of stuff you need to remember by orders of magnitude,
organizes that stuff to make it easier to remember,
easier to see what you can do with it,
and where to go next.

Not clear to me (yet) whether category theory is this kind of
``right abstraction''. 

Certainly, all the introductions I've seen so far have much more
the feel of explaining determinants as a mysterious,
out-of-the-blue (and numerically unstable) algorithm,
that just happens to play a part in ``inverting'' a matrix,
where the concept of ``inversion'' itself is not 
function inverse, or group element inverse,
but rather a complicated construction of a matrix that
just happens to give a unit diagonal matrix when multiplied with 
the original.

%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}}
\levelstay{Why?}
\label{sec:Why?}

\setlength{\epigraphwidth}{0.95\linewidth}

\epigraph{Category theory provides a language to describe precisely many similar phenomena that
occur in different mathematical fields. For example,
\begin{enumerate}
  \item  Each finite dimensional vector space is isomorphic to its dual and hence also to its
second dual. The second correspondence is considered “natural”, but the first is
not. Category theory allows one to precisely make the distinction via the notion
of natural isomorphism.
\item Topological spaces can be defined in many different ways, e.g., via open sets, via
closed sets, via neighborhoods, via convergent filters, and via closure operations.
Why do these definitions describe “essentially the same” objects? Category theory
provides an answer via the notion of concrete isomorphism.
\item Initial structures, final structures, and factorization structures occur in many different
situations. Category theory allows one to formulate and investigate such
concepts with an appropriate degree of generality.
\end{enumerate}
\leavevmode }
{Ad\'{a}mek, Herrlich, Strecker, 
\textit{Abstract and Concrete Categories:
The Joy of Cats}~\cite{adamek-herrlich-strecker-1990}}

\pagebreak

\epigraph{In addition to its direct relevance to theoretical knowledge and current applications, category theory
is often used as an (implicit) mathematical jargon rather than for its explicit notions and results.
Indeed, category theory may prove useful in construction of a sound, unifying mathematical
environment, one of the purposes of theoretical investigation. As we have all probably experienced, it
is good to know in which “category” one is working, i.e., which are the acceptable morphisms and
constructions, and the language of categories may provide a powerful standardization of methods and
language. In other words, many different formalisms and structures may be proposed for what is
essentially the same concept; the categorical language and approach may simplify through abstraction,
display the generality of concepts, and help to formulate uniform definitions. This has been the case,
for example, in the early applications of category theory to algebraic geometry.}
{Asperi and Longo, \textit{Categories, Types, and Structures: 
an introduction to Category Theory for the working computer scientist}~\cite{asperti-longo-1991}}

%\pagebreak
\epigraph{Okay, you wanna know what a topos is? 
First I'll give you a hand-wavy vague explanation, 
then an actual definition, 
then a few consequences of this definition, 
and then some examples.
\par
I'll warn you: 
it takes a lot of work to learn enough topos theory 
to really use it to solve problems. 
Thus, when you're getting started the main reason to learn 
about it should not be to quickly solve some specific problems, 
but to broaden your horizons and break out of the box 
that traditional mathematics, based on set theory, 
imposes on your thinking.}
{Baez, \textit{Topos theory in a 
nutshell}~\cite{baez-2017-topos-theory-nutshell}}

\pagebreak

\epigraph{Categories originally arose in mathematics out of the need of a formalism to
describe the passage from one type of mathematical structure to another. A
category in this way represents a kind of mathematics, and may be described
as category as mathematical workspace.
A category is also a mathematical structure. As such, it is a common
generalization of both ordered sets and monoids (the latter are a simple
type of algebraic structure that include transition systems as examples),
and questions motivated by those topics often have interesting answers for
categories. This is category as mathematical structure.
A third point of view is emphasized in this book. A category can be seen
as a structure that formalizes a mathematician's description of a type of
structure. This is the role of category as theory. Formal descriptions in
mathematical logic are traditionally given as formal languages with rules for
forming terms, axioms and equations. Algebraists long ago invented a formalism
based on tuples, the method of signatures and equations, to describe
algebraic structures. In this book, we advocate categories in their role as formal
theories as being in many ways superior to the others just mentioned.
Continuing along the same path, we advocate sketches as definite specifications
for the theories.}
{Barr and Wells, \textit{Category theory for computing science}~\cite{barr_wells_2020}}

%\pagebreak
\epigraph{Category theory is becoming a central hub for all of pure mathematics. It is unmatched
in its ability to organize and layer abstractions, to find commonalities between structures
of all sorts, and to facilitate communication between different mathematical
communities.}
{Fong and Spivak, \textit{Seven Sketches in Compositionality: 
An Invitation to Applied Category Theory}~\cite{fong-spivakd2018-seven-sketches}}

\pagebreak
\epigraph{In each area of mathematics 
(e.g. groups, topological spaces) 
there are available many definitions and constructions.
It turns out, however, that there are a number of notions
(e.g. that of a product) that occur naturally 
in various areas of mathematics, with only slight changes from
one area to another.
It is convenient to take advantage of this observation.
Category theory can be described as that branch of mathematics
in which one studies certain definitions in a broader context---without
reference to the particular area 
in which the definition might be applied.
It is the ``mathematics of mathematics''.}
{Geroch, \textit{Mathematical Physics}~\cite{geroch-1985}}

%\pagebreak
\epigraph{Since its first introduction over 60 years ago, the concept of category has been
increasingly employed in all branches of mathematics, especially in studies where the
relationship between different branches is of importance. The categorical ideas arose
originally from the study of a relationship between geometry and algebra; the
fundamental simplicity of these ideas soon made possible their broader application.
\par
The categorical concepts are latent in elementary mathematics; making them more
explicit helps us to go beyond elementary algebra into more advanced mathematical
sciences.}
{Lawvere and Schanuel, 
\textit{Conceptual Mathematics: 
A First Introduction to Categories}~\cite{lawvere-schanuel-2009}}

\pagebreak
\epigraph{Category theory takes a bird’s eye view of mathematics. From high in the sky,
details become invisible, but we can spot patterns that were impossible to detect
from ground level. How is the lowest common multiple of two numbers
like the direct sum of two vector spaces? What do discrete topological spaces,
free groups, and fields of fractions have in common?We will discover answers
to these and many similar questions, seeing patterns in mathematics that you
may never have seen before.
\par
The most important concept in this book is that of universal property. The
further you go in mathematics, especially pure mathematics, the more universal
properties you will meet. We will spend most of our time studying different
manifestations of this concept.
\par
Like all branches of mathematics, category theory has its own special vocabulary,
which we will meet as we go along. But since the idea of universal
property is so important, I will use this introduction to explain it with no jargon
at all, by means of examples.}
{Leinster, \textit{Basic Category Theory}~\cite{leinster-2016-basic-category-theory}}

%\pagebreak
\epigraph{\ldots On the first level, categories provide
a convenient conceptual language, based on notions of category, 
functor, natural transformation, contravariance, and
functor category.
\ldots Next comes the fundamental idea of an adjoint pair of functors.
This appears in many equivalent forms: that of universal construction,
that of direct and inverse limit, 
and that of a pair of functors with a natural isomorphism between
corresponding sets of arrows. \ldots
The slogan is ``Adjoint functions arise everywhere.''
\par
Alternatively, the fundamental notion of category theory is that
of a monoid---a set with a binary operation of multiplication
that is associative and that has a unit;
a category itself can be regarded as a sort of generalized monoid.
\ldots
\par
Since a category consists of arrows, our subject could be 
described as learning how to live without elements, using arrows
instead.
}
{MacLane, \textit{Categories for the working
mathematician}~\cite{maclane-1998-working-mathematician}}

\pagebreak
\epigraph{Atiyah described mathematics as the
“science of analogy.” In this vein, the purview
of category theory is mathematical analogy. 
Category theory provides a cross-disciplinary
language for mathematics designed to delineate general phenomena,
which enables the
transfer of ideas from one area of study to another. 
The category-theoretic perspective can
function as a simplifying abstraction, isolating propositions 
that hold for formal reasons
from those whose proofs require techniques particular 
to a given mathematical discipline.}
{Riehl, 
\textit{Category Theory in Context, Preface
}~\cite{riehl2017}}

\pagebreak
\epigraph{This course is an attempt to extol the virtues of a new branch of mathematics,
called category theory, which was invented for powerful communication of ideas between
different fields and subfields within mathematics. By powerful communication of ideas I
actually mean something precise. Different branches of mathematics can be formalized
into categories. These categories can then be connected together by functors. And the
sense in which these functors provide powerful communication of ideas is that facts and
theorems proven in one category can be transferred through a connecting functor to
yield proofs of analogous theorems in another category. A functor is like a conductor of
mathematical truth.
\par
I believe that the language and toolset of category theory can be useful throughout
science. We build scientific understanding by developing models, and category theory is
the study of basic conceptual building blocks and how they cleanly fit together to make
such models. Certain structures and conceptual frameworks show up again and again in
our understanding of reality. No one would dispute that vector spaces are ubiquitous.
But so are hierarchies, symmetries, actions of agents on objects, data models, global
behavior emerging as the aggregate of local behavior, self-similarity, and the effect of
methodological context.
\par
Some ideas are so common that our use of them goes virtually undetected, such as set theoretic
intersections. For example, when we speak of a material that is both lightweight
and ductile, we are intersecting two sets. But what is the use of even mentioning this
set-theoretic fact? The answer is that when we formalize our ideas, our understanding
is almost always clarified. Our ability to communicate with others is enhanced, and the
possibility for developing new insights expands. And if we are ever to get to the point
that we can input our ideas into computers, we will need to be able to formalize these
ideas first.
\par
It is my hope that this course will offer scientists a new vocabulary in which to think
and communicate, and a new pipeline to the vast array of theorems that exist and are
considered immensely powerful within mathematics. These theorems have not made their
way out into the world of science, but they are directly applicable there. Hierarchies are
partial orders, symmetries are group elements, data models are categories, agent actions
are monoid actions, local-to-global principles are sheaves, self-similarity is modeled by
operads, context can be modeled by monads.}
{D. Spivak, \textit{Category Theory for Scientists 
(old version)}~\cite{spivakd2013}}

\pagebreak
An alternative to first order logic, sets, 
and functions as a foundation for all
mathematics~\cite{feferman1977Categorical},  
particularly topos theory.


%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}}
\levelstay{Doubts}
\label{sec:Doubts}

Possible problems with category theory that should be examined.


\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{Hype}
\label{sec:Hype}

Much of what's written about category theory feels like marketing.
I read many pretty vague claims about its value
(or perhaps I just don't understand the more specific claims).
Then I pick up some introductory text,
and after $\sim 500$ pages of progressively less and less 
intuitive definitions, and unconvincing examples in category Sets,
or maybe category Monoids,
but still no actual evidence of anything that wouldn't have been
easier and simpler in the original context.

A possible symptom that's something wrong:
Category theory, which originated in $1940$--$1950$s,
is still, in $2013$, $60+$ years, later being described in terms like:
``This course is an attempt to extol the virtues of a new branch of mathematics,
called category theory, which was invented for powerful communication of ideas between
different fields and subfields within mathematics.''~\cite{spivakd2013}.
It doesn't seem like such assertions would be necessary,
if it really were the 'right' way to unify 
and illuminate all of mathematics.

It feels similar to introductions to the related subject of
'functional' programming languages,
where the rightness of (statically typed) functional programming 
is taken as
an article of religious faith that doesn't need to be justified
(for an exception, which lacks elaborate type systems,
see SICP~\cite{Abelson1996}).
Many introductions to functional programming spend their
effort demonstrating how, with a lot of effort, you can do
something trivial is most other languages
via a contorted jesuitical lip service to the religious tenets.

\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{Shaky foundations}
\label{sec:Shaky-foundations}

\epigraph{On the most fundamental level, the foundations of mathematics are much shakier
than the mathematics that we do. Most mathematicians adhere to foundational
principles that are known to be polite fictions. For example, it is a theorem that
there does not exist any way to ever actually construct or even define a well-ordering
of the real numbers. There is considerable evidence (but no proof) that we can get
away with these polite fictions without being caught out, but that doesn’t make
them right. Set theorists construct many alternate and mutually contradictory
“mathematical universes” such that if one is consistent, the others are too. This
leaves very little confidence that one or the other is the right choice or the natural
choice. {\Godel}’s incompleteness theorem implies that there can be no formal system
that is consistent, yet powerful enough to serve as a basis for all of the mathematics
that we do.}%
{Thurston, \textit{On proof and progress in mathematics}~\cite{thurston1994proof}}

\pagebreak

\epigraph{The point is simply that when explaining the general notion of
structure and of particular kinds of structures such as groups, rings,
categories, etc. we implicitly presume as understood the ideas of
operation and collection; e.g. we say that a group consists of a collection
of a objects together with a binary operation satisfying such and
such conditions. Next, when explaining the notion of homol1wrphism
for groups or functor for categories, etc., we must again understand the
concept of operation. Then to follow category theory beyond the basic
definitions, we must deal with questions of completeness, which are
formulated in terms of collections of morphisms. Further· to verify
completeness in concrete categories, we must be able to form the
operation of Cartesian product over collections of its structures. Thus
at each step we must make use of the unstructured notions of operation
and collection to explain the structural notions to be studied. The
logical and psychological priority if not primacy of the notions of
operation and collection is thus evident.
\par
It follows that a theory whose objects are supposed to be highly
structured and which does not explicitly reveal assumptions about
operations and collections cannot claim to constitute a foundation for
mathematics, simply because those assumptions are unexamined. It is
evidently begging the question to treat collections (and operations
between them) as a category which is supposed to be one of the objects
of the universe of the theory to be formulated.
\par
The foundations of mathematics must still be pursued in a direct
examination of the notions of operation and collection. There are at
present only two (more or less) coherent and comprehensive approaches
to these, based respectively on the Platonist and the constructivist
viewpoints. Only the first of these has been fully elaborated,
taking as basis the conception of sets in the cumulative hierarchy. It is
distinctive of this approach that it is extensional, i.e., collections are
considered independent of any means of definition. Further, operations
are identified with their graphs.}
{Feferman,
\textit{Categorical Foundations and Foundations of Category 
Theory}~\cite{feferman1977Categorical}}

%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{Complexity}
\label{sec:Complexity}

\epigraph{
\textsl{Und was wird der geduldige Leser am
Schlusse sagen? Dass der Verfasser mit einem Aufwande von uns/iglicher Arbeit es gliicklich
erreicht hat, die klarsten Vorstellungen in ein unheimliches Dunkel zu hiillen!}
\par
(What will the forbearing reader say at the end? That the author, in a squandering of indescribable
work, has happily managed to surround the clearest ideas in a disturbing obscurity!
)}%
{Dedekind to Klein, April 1888, 
from~\cite{dugac1976DedekindFondements},
as quoted in~\cite{ferreiros2007labyrinth}.}

A problem for novices is depth of definition and theorem
(and, worse, concept) dependence.

The constructs do not feel natural, in themselves, 
to the uninitiated.
Examples: product/sum, epi/monomorphisms, ...

The general feel is like a student who manages to solve a problem
by quasi-random search over possible next steps,
stumbling their way to the desired result,
without any coherent overview or intuition.

A telltale symptom of bad math is when the premise of a theorem
(or the necessary definition) is so complicated and arbitrary,
and difficult to verify in any practical setting,
that it seems more reasonable to just assume the conclusion,
and skip the intervening nonsense.
(eg many central limit theorems are like this).

Is part of the attraction due to the (unnecessary?)
complexity providing opportunities for lots of
least-publishable-unit theorem-credits?

\textbf{Question:} Are there reasonable quantitative measures
of the complexity of a theory/subject/textbook?
For example, something computed from the DAG of
definition/theorem dependencies?
Anything in software complexity measures that would apply?

\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{Is an arrow more general than a function?}
\label{sec:arrow-more-general}

\epigraph{\ldots the whole concept of a category is essentially 
an auxiliary
one; our basic concepts are essentially those of a functor and of
a natural transformation {\ldots}. 
The idea of a category is required
only by the precept that every function should have a definite
class as domain and a definite class as range, for the categories
are provided as the domains and ranges of functors. Thus one
could drop the category concept altogether and adopt an even
more intuitive standpoint, in which a functor such as ‘Hom’ is
not defined over the category of ‘all’ groups, 
but for each particular
pair of groups which may be given. The standpoint would
suffice for the applications, inasmuch as none of our developments
will involve elaborate constructions on the categories
themselves.}
{Eilenberg and 
MacLane~\cite[p~247]{eilenberg-maclane-1945-general},
quoted in Landry and 
Marquis~\cite[p~3]{landry-marquis-2005-cat-theory-context)}}

Do functors really need definite (co)domains?

There's a fair amount of arbitrariness 
to the domain and codomain of a function.
Given a (procedural) function,
we can choose any superset of the range as the codomain.
We can also restrict a function to any subset of the domain,
and it may be important to know that one function is a simple 
restriction another --- is there a reasonable way to do this
for arrows?

Any function that takes elements of a set $\Set{X}$
and returns elements of a set $\Set{Y}$
is, or is intimately connected to, 
a function that takes subsets of $\Set{X}$ and returns
subsets of $\Set{Y}$.

For any function, we can expand the domain, by considering partial
functions. 
Partial functions may be necessary in a computable context,
since we don't in general know if a given function will
halt for all elements of the domain.
The closer we get to real computation, the more we may need to
handle exceptional return values, ie, replace the natural
codomain by its union with a set of error/exception objects.

Category theory abstracts functions between sets to
arrows (maps, morphisms) between objects,
with the co/domain objects part of the identity of the arrow.

%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{Modularity breaking}
\label{sec:Modularity_breaking}

Modularity a key design principle, whether for
a physical system, software, or formal theory.

I am beginning to think one of the issues with category theory
is a tendency to break the modularity of the constructs it's
``abstracting''.

One example is, again, functions vs arrows.
As mentioned in section~\ref{sec:arrow-more-general},
the association of a function and its domain, and, particularly,
codomain is ,in practice, pretty loose.
Modifying a function by restricting, extending , or otherwise
modifying the domain and/or codomain is common.
ALthough it's not usually clearly stated, 
I think most operate as though there is a common entity
that's shared by all these essentially trivial variations on the
same function.
As far as I know, category theory does not provide anything similar:
no way to construct a new arrow by modifying the domain
and codomain of the original, while maintaining other properties.

More generally, I think I am beginning to see a pattern where
constructs that are modular in a sets and functions context,
in the sense that they only depend on an individual function or
set, or perhaps a few such, require global information about
the whole category.
For example, whether a function is one-to-one or onto
can be determined from the function in isolation,
or, at most, using the (co)domain.
Determining whether an arrow is mono or epi requires
considering all other arrows that share the (co)domain,
and what the $c\mathsf{compose}$ operation does in those cases.

I imagine a counter-argument along the lines of:
moving only the necessary, minimal semantics out of the ``atomic''
inner component entities, 
into the surrounding structure (the category) allows the same 
outer structure to be used
with other atomic entities, and hopefully, significant results
can then be obtained, independent of the inner components.
(I'm almost surely not doing real justice to this kind of argument.)
In any case, I think it's wrong.

I suspect there's a useful analogy to data structure design.

At one end of a spectrum, code is built out of conceptually 
``large'' objects, encapsulating considerable state and
behavior. In any particular context, only a limited interface
is used, depending on a small subset of the state and behavior,
with the code otherwise independent of the hidden functionality.
When objects like this are held in collections, those collections
tend to be simple, eg lists, with almost no assumptions
about what the elements of the list are.
This kind of code is more common in languages developed 
after $1990$.

At the other end of the spectrum are systems where the semantics
are diffused from the elements into the surrounding collection.
In such systems, the elements are typically restricted 
to a few primitive types (eg integers, floats, strings).
Such systems go back to the $1960$s, 
and, although still in wide use,
plague those who must deal with them (as I can attest from personal
experience).
Such systems result in bug-ridden, inefficient, 
inflexible, brittle code.

(\textbf{TODO:} More complete examples? 
How much detail is actually useful to anybody?)

One example is Fortran. The only data structure is the array.
The meaning of any array can only be determined examining every
place in the code where that array might be touched.

Another is relational databases. The semantics is determined
by which tables are joined to which on what columns.
It is piratically impossible to add functionality to a system
built on relational databases without starting from scratch.

R, Matlab (array/relation languages with some modern features
patched on) vs Python.



%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{Right abstraction?}
\label{sec:Right-abstraction}

Is category theory a good language?~\cite{wiki:Abstract-nonsense-2020}

Is part of the attraction due to being able accumulate
theorem-credits by publishing
new proofs of old results?

Are claims of additional insight justified?

Are there any significant categories 
that don't reduce to something like sets and functions?
``Significant'' meaning not just the completion of an arbitrary
directed multigraph.

For example, 

Is there something more like ``sets and functions'' where
the standard constructs make sense?

Is this question related to concrete 
categories?~\cite{wiki:concrete-category-2020}

%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{Naming}
\label{sec:Naming}

Is category theory a good language?~\cite{wiki:Abstract-nonsense-2020}

Generally, mathematicians aren't good at naming:
eg, what's round about a ring?

Particularly bad in category theory, eg, 
what's ``commuting'' in a commuting diagram.

Prefer self-explanatory names, even if a bit longer:
eg, ``left (right) cancelable'' rather than ``mono(epi)morphism'',
``structure-preserving function'' over ``homomorphism''.

``Morphism'' etymology.

Is part of the attraction the sense of being to utter magic 
incantations only understood by the initiated?

 
%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{Graphical languages}
\label{sec:Graphical-languages}

Idea that won't die. 
Not completely without value, 
but very limited in terms of the complexity of ideas that can be
expressed.

Another problem is that graphical languages don't lend themselves
to ``computation''
in the same way that text-based languages do,
particularly math notation .~\cite{dutilh_novaes_2012}.

%-----------------------------------------------------------------
%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}}
\levelstay{Foundational Sketch}
\label{sec:Foundational-Sketch}

In this section, I am going to lay out a basis for
the discussions of category and topos theory to follow. 
I will be intentionally vague, at least in parts;
I have ideas about what I want in a foundation 
for math and computing, but they are incomplete, at best,
if not actually contradictory.

In my training, to the extent that anything 
foundational was encountered,
it was what I believe people refer to as ``standard'' or
``classical'' foundations,
in more-or-less the tradition of Cantor, Russell, Hilbert, etc.
Probably more naive set theory~\cite{Halmos1960Naive} 
than any formal axiomatic approach.

More recently, I've done enough reading in 
computable reals and constructive 
analysis~\cite{henle:2012:numbers,Bridger:2019}
to doubt the necessity of more-than-countable infinity,
axiom of choice, non-measurable sets, {\ldots},
at least for ``scientifically applicable'' 
mathematics.~\cite{feferman1989CantorNecessary,
feferman1992LongWay}

At this point, I recognize terms like
``constructivist'', ``intuitionistic'', ``predicative'', 
``finitary'', ``formalist'', ``platonist'', ``realist'', {\ldots},
though I couldn't say with confidence exactly what any of them
mean. 
I suspect no $2$ people working in these areas would define these
terms in exactly the same way.
My exploration of computable reals left me very confused,
which was only partially relieved when I realized there are 
something like a dozen schools of intuitionistic/constructive
mathematics, sometimes using different words to mean the
same thing, sometimes the same words to mean different things.

%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{What would a good foundation look like?}
\label{sec:good-foundation}

Goals:
\begin{enumerate}
  \item Support all ``scientifically applicable mathematics''.
  (Really, support the mathematics I want to use.) \par
  \textbf{TODO:} start listing problems of interest,
  and what kinds of math are needed to pose and solve them.
  
  \item Appropriately ``high level''. \par
  My goals in (attempting) to define a foundation are fundamentally
different from classical approaches,
many of which try to ``implement'' all of mathematics starting from
something primitive, like a hierarchy of pure sets.
This is loosely analogous, in the context of software,
to implementing everything binary.
I'm looking for a foundation that is more convenient (for me),
in the same sense that a modern programming language is more
convenient than assembly language (for most problems).
Note that high level programming languages are also more general
than the instruction set of a particular machine.
A good foundation ought to be similar in the sense of being
``implementable'' in a variety of primitive bases.

  \item No dangling definitions, no dependence on informal metalanguage.
   \par
  Category theory starts with sets of objects and arrows, 
  and functions on them. Almost all the introductions I've seen 
  take these notions for granted, hand waving over issues arising
  from sets that are ``too big'', eg, the set of all sets needed
  for the objects in category Sets.
  \par
  Conventional set theory is defined using first order logic,
  which depends on a formal language, which is defined with
  reference to an ``alphabet'' (or ``vocabulary''), 
  a set of symbols, and and a set of
  operations (functions) used to combine symbols into legal 
  expressions, and a set of inference rules (functions) that map
  expressions to expressions. I haven't found anywhere that
  addresses this circularity in the foundation of set theory,
  except for occasional hand-waving about first order logic
  being a formal language whose metalanguage is informal.
  \par
  Likely result is circular (non-predicative) definitions:
  eg, sets defined using sets.
  
  \item Self-defining: expressed in a formal language
  without meta-language. \par
  Any decent programming language
  is/can be implemented in itself and allows you to define 
  procedures that call themselves. \par
  I know that this
  contradicts (what I believe to be) the Tarskian consensus about
  the impossibility of defining ``truth'' without a metalanguage
  in which to define it. It also contradicts the various 
  mechanisms introduced into variations of set theory intended to
  prevent the self-referential and counting (too large sets) 
  paradoxes that caused the 
  ``crisis in the foundation of mathematics'' of the first few
  decades of the $1900$s.
  I speculate that an alternative approach is to view these
  ``antinomies'' as corresponding to procedures that never halt,
  an unavoidable reality.
  
  \item Start from a model for computation/procedures, ie, something 
  equivalent to
  Turing machines or lambda calculus, but probably more convenient,
  closer to actual programming languages.
  
  \item Nothing more than countable infinity, or finite but unbounded,
  if possible.
  I think this may be implied any computation model where
  procedures are executed in discrete steps, unless you allow
  the data to include completed infinities.
\end{enumerate}

%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{A sketch}
\label{sec:sketch}

An incomplete try at a foundation:
\begin{description}

\item[Universe]\mbox{}\\
A ``set'' of identifiable, distinguishable
things,
and some notion of a reference to a thing, distinct from the thing
itself.
A primitive of this approach is the ability, given $2$ references,
to determine if they refer to the same thing.
\par
(\textbf{Question:}
Is this right? What do I mean when I write $x=y$?
Seems like usual case is we know something about what $x$ and $y$
refer to, but not the specific things.)
\par
API. 
\par
\textsf{true} and \textsf{false} as things?
\par
Every thing mentioned below is a first class thing in the universe.
% Many of these things contain references to other things.
% Some of these things are sets,
% some are atoms (aka ``ur-elements''~\cite{wiki:Urelement}). \\
% Many versions of set theory do without 
% atoms~\cite{wiki:Constructible_universe,wiki:Von_Neumann_universe},
% starting from the empty set, implementing $\mathcal{N}$
% (and everything else of interest) via various sets of sets that
% bottom out with $\emptyset$.

\item[Values vs references to values]\mbox{}\\

\item[Language]\mbox{}\\
Some formal language that allows us 
to construct references to things in the universe, 
follow chains of references, and compute and infer facts 
about things and their references. 
For me, a good language should self-describing, without the
language, metalanguage, first order, second order, higher order 
distinctions in standard formal logic.
\par
Every thing in the language an element of the universe.

\item[(Data) Structure]\mbox{}\\
(need as better name)
A structure is collection of references with
some mechanism for getting at the (eg a path language).

\item[Set]  \mbox{}\\
Direct sets or indirect via references?
Set identity via elements?
Bounded finite, unbounded finite, countable, \ldots ?

\item[Tuple, Cartesian products]\mbox{}\\

\item[Functions as procedures]\mbox{}\\
In contrast to function as graph relation.
Arbitrariness of (co)domains. Partial functions. Failure to halt.
error return independent of (co)domains)?.

\item[Functions as relations]\mbox{}\\

\item[Mathematical structures]\mbox{}\\
sets plus functions with constraints/assertions.
\par
Standard structures defined with ``natural'' (subjectively, to me)
properties of the functions. 
\par
For example, a group is commutative or not, depending on whether
the group operation function is symmetric: $f(x,y) = f(y,x)$.
\par
Distributive properties are similarly fairly obvious (again, to me)
simplifying assumptions that might or might not be true of
a structure's functions: 
$\otimes (a,\oplus (x,y)) = \oplus (\otimes (a,x), \otimes (a,y))$
(infix version: 
$a \otimes (x \oplus y) = (a \otimes x) \oplus (a \otimes y)$).

\item[Structure-preserving functions]\mbox{}\\
Function needs to be defined on the (disjoint) union of the 
structure's sets.
And needs to ``commute'' with the structure functions.
For example, linear spaces and functions: 
Suppose $f : \Space{X} \rightarrow \Space{Y}$
is effectively $2$ functions:
$f : \mathsf{scalars}(\Space{X}) \rightarrow \mathsf{scalars}(\Space{Y})$ and
$f : \mathsf{vectors}(\Space{X}) \rightarrow \mathsf{vectors}(\Space{Y})$.
 
A linear function preserves the linear structure:
\begin{equation}
f \big( (a_0 \, *_{\scriptscriptstyle\Space{X}} \, \Vector{x}_0) 
\: +_{\scriptscriptstyle\Space{X}} \: 
(a_1 \, *_{\scriptscriptstyle\Space{X}} \, \Vector{x}_1) \big)
\; = \; 
\big( f(a_0) \, *_{\scriptscriptstyle\Space{Y}} \, f(\Vector{x}_0) \big) 
\: +_{\scriptscriptstyle\Space{Y}} \: 
\big( f(a_1) \, *_{\scriptscriptstyle\Space{Y}} \, f(\Vector{x}_1) \big)
\end{equation}
where $*_{\scriptscriptstyle\Space{X}}, +_{\scriptscriptstyle\Space{X}}, 
*_{\scriptscriptstyle\Space{Y}}, +_{\scriptscriptstyle\Space{Y}},$
are the scalar multiplication and addition operations on the $2$ spaces.
\end{description}

Issues: 
\begin{itemize}
  \item finite/countable computation vs inference that determine
something for uncountable entities.
  \end{itemize}

%-----------------------------------------------------------------
%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}}
\levelstay{Key ideas in category/topos theory}
\label{sec:Key-ideas}

Things various authors claim are important or valuable;
things that ought to be understood,
and ought to be presentable in a natural, intuitive way:
\begin{itemize}
  \item Topos, elementary topos: 
  category ``essentially the same as \textbf{Set}''
  \item subobject (classifier)
  \item Cartesian closed category
  \item initial, terminal object
  \item product, sum/coproduct, exponential, meet, join
  \item mono/epi morphism
  \item split/retraction,/isomorphism
  \item duality/opposite
  \item equalizers
  \item limits
  \item pullback/pushout
  \item completeness
  \item universal (mapping) property
  \item adjointness
\end{itemize}

%-----------------------------------------------------------------
%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}}
\levelstay{Example categories}
\label{sec:Example-categories}

One question to be examined here is: are there any meaningful
categories that aren't some version of a collection of sets
and a collection of functions between? 
By ``meaningful'', I mean that the key ideas 
in section~\ref{sec:Key-ideas} apply
and are useful in some way.
And, in any of the cases, 
does categorical language help or hurt?

\begin{itemize}
  \item Sets of sets and sets of functions between them.
Sometimes relations rather than functions.
More specifically, mathematical structures of a given ``type'' and
structure-preserving functions between them.

  \item Monoids, groups, etc. \par
  Each monoid category has a single object which can be taken as
  corresponding to the set of elements. The arrows correspond to 
  individual elements, or to the functions obtained from partial
  evaluation of the monoid operation: 
  $f_A(\_)= \circ (A,\_) = A \circ \_$.\par
  One obvious problem with this is that it excludes about half of
  the group-like, one set, one operation structures~\cite{wiki:Magma}: 
  the ones without identity. 
  An example where identity arrows are a problem. \par
  Also, seems clear that many of the key categorical constructs
  don't apply, raising even more questions about whether there's
  any value.
  
  \item Pre-ordered sets, partially ordered sets, including
  inclusion ordering in topology.
  
  
  \item ``Discrete'' categories. Object are elements of a set; 
  only arrows are identities, one per element. 
  (Another example where identity arrows are problematic.)
  Almost surely of no value.
  
  \item Completion of arbitrary directed graph; 
  almost surely of no value, at least on its own.
  This includes things commonly represented as directed graphs,
  without any additional categorical structure, like ontologies~\cite{spivakd:2013},
  state transition diagrams, dependency graphs, etc.
  Do categorical completion and constructs help with anything?
  
  \item Types signatures in ``functional'' programming.
  
  \item Categories of arrows, categories, functors, etc.
  Is there anything here beyond certain sets and functions between
  them?
  \item Slice categories~\cite[sec~2.6.10]{barr_wells_2020}
\end{itemize}
%-----------------------------------------------------------------
%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}}
\levelstay{Bottom up}
\label{sec:Bottom-up}

Start from directed (multi)graph~\cite{wiki:Directed_graph}.
Categorical constructs are pretty much impossible to motivate
in this context.

In this section, I'm going to use graph terminology,
eg, ``vertex'' and ''edge'', rather than ``object'' and ``arrow'',
but I will follow the category theory convention of
upper case letters for vertices/objects and lower case for
edges/arrows.

\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{Directed graph}
\label{sec:Directed_graph}

(\textbf{Question:}
 any value is thinking about undirected graphs?
 Simplicial complexes?)

\textit{Directed graph} (aka digraph): 
an ordered pair $G=\left( \Set{V}, \Set{E} \right)$,
where $\Set{V}$ is a set of \textit{vertices}, 
$\Set{E}$ a set of \textit{edges}, ordered pairs of vertices.
$A$ is the \textit{tail} and $B$ the \textit{head}
of $\left(A,B\right)$.

In (computational) applications, $\Set{V}$ and $\Set{E}$ 
are finite, perhaps unbounded finite,
but, in general, they need not be.

It's common to assume 
\begin{enumerate}
\item there is at most one edge
in a graph connecting any $2$ vertices.\par
(\textbf{Question:} does ``ordered pair'' imply uniqueness?
In other words, can we have multiple distinct copies of
 $\left(A,B\right)$, pairing the same elements $A$ and $B$?
 If we use one of the primitive set theory ``implementations'',
 then there is only one $\left(A,B\right)$ 
 for given $A$ and $B$.)
\item the vertices in an edge must be 
distinct (no loop edges).
\end{enumerate}

A graph may be called a \textit{multigraph} when $1$ is
not assumed.
In a context where loops are allowed,
a graph with no loops may be called \textit{simple}.

(\textbf{Question:} 
Digraph special case of (oriented) simplicial complex.
What's the difference between a simplicial complex 
and a hypergraph?)

A \textit{path} is a sequence of edges where the head of each
edge matches the tail of the following edge, if there is one.
An \textit{directed acyclic graph} (aka DAG) has no paths
connecting a vertex to itself.
A directed graph is \textit{(strongly) connected} if there is a path
from any vertex to any other (weakly if there is path
ignoring direction.

(\textbf:{TODO:} straighten out \textit{path} vs \textit{walk} vs
\textit{trail}; directed vs undirected; sequence of alternating
vertices and edges, starting and beginning with a vertex.)

A \textit{root} vertex (aka source) has no entering edges.
A \textit{leaf} vertex (aka sink) has no departing edges.

A \textit{tree} is a directed graph with one root, 
where all vertices have at most entering edge.

(Mesh) \textit{dual} of a graph interchanges the roles of edges 
and vertices, resulting in a hypergraph where every dual vertex
has exactly $2$ edges. 
(\textbf{Question:} orientation/direction of dual edges?~\cite{rusnak2012oriented})
(Other notion of dual of planar graph interchanges vertices and ``faces'',
orientation from $90^{\circ}$ turn of primal edge.~\cite{wiki:Dual_graph})

An example:
\begin{figure}
\centering
\fbox{
\begin{tikzcd}[
row sep=1.2cm, 
column sep=2.5cm,
ampersand replacement = \&,
%execute at begin picture={
%     \useasboundingbox (-5.15,-3.35) rectangle (4.25,3.4); }
    ]
V_0
\arrow[drr, "e_{02}", bend left]
\arrow[ddr, "e_{03}"', bend right]
\arrow[dr, "{e_{01}}"] 
\& 
\& 
\\
\& 
V_1 
\arrow[r, "e_{12}"] 
\arrow[d, "e_{13}"']
\& 
V_2 
\arrow[d, "e_{24}"] 
\\
\& 
V_3 
\arrow[r, "e_{34}"']
\& V_4
\end{tikzcd}
}
\caption{A directed graph}
\label{fig:a_digraph}
\end{figure}

$V_0$ is the only root; $V_4$ is the only leaf;
the graph is simple, connected, and acyclic.

Applications of directed graphs:~\cite{clrs-2009}
\begin{itemize}
  \item Transportation networks
  \item Shortest path
  \item Predict travel time
  \item Maximum flow
  \item network design/optimization
  \item connected components
  \item spanning trees
  \item dependencies among modules, tasks, definitions/theorems
  \item finite state machines, state-transition diagrams
  \item continuation-passing code (no automatic return to caller)
  \item graph layout (mapping vertices to $2$d points).
\end{itemize}

%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{Category}
\label{sec:Category_from_digraph}



A \textit{category} is a directed (multi) graph 
together with $2$ functions that satisfy certain constraints:
\begin{description}
\item[Composition]\mbox{}\\
At least $2$ ways to think about this. 
More common way first, better (?) way second.
\begin{description}
\item[Binary]\mbox{}\\
The usual way this is posed is for pairs of connected edges:
Whenever $\mathsf{tail}(e0) = \mathsf{head}(e_1)$,
then
\[ \mathsf{compose}(e_0,e_1) = e_{10} \]
is defined
for some $e_{10}$ among the edges of the graph,
with $\mathsf{tail}(e_{10}) = \mathsf{tail}(e_1)$
and $\mathsf{head}(e_{10}) = \mathsf{head}(e_0)$.
(Note the potential for confusion 
in the ordering of the arguments to $\mathsf{compose}$;
general idea is that $e_1$ is traversed/applied first,
then $e_0$.)
\par
In addition, $\mathsf{compose}$ is required to be associative:
\begin{align*}
\mathsf{compose}(\mathsf{compose}(e_0,e_1),e_2) 
&
= \mathsf{compose}(e_0,\mathsf{compose}(e_1,e_2))
\\
&
= \mathsf{compose}(e_0,e_1,e_2)
\end{align*}

\item[General paths]\mbox{}\\
An alternative is define the domain of $\mathsf{compose}$
to be the graph's paths. 
Then, for all paths $p$ in the graph,
there exists some edge $e$ in the graph
with 
\begin{equation*}
\mathsf{compose}(p) = e
\end{equation*} 
such that 
$p$ and $e$ have the same head and tail.
Associativity here means that if we partially reduce a path
by applying $\mathsf{compose}$ to a sub-path,
and then $\mathsf{compose}$ the partially reduced path,
we get the same edge as composing the whole path.
\end{description}
\par
Either way we define $\mathsf{compose}$ (no reason not to do both
simultaneously), it is clearly (to me) not a natural construct
for directed graphs: for every path, there is also 
a single edge directly connecting its tail to its head.
And associativity imposes strong constraints on which of the possibly
many such single edges can be chosen as the value of $\mathsf{compose}$.
I don't know of any non-categorical applications of directed graphs
for which this makes sense.
Moreover, it's not clear that any of this is really necessary.
\par
$\mathsf{compose}$ is used primarily, if not exclusively,
to define whether $2$ paths are equivalent, by asserting they 
compose to the same edge.
\par
(\textbf{Question:} are $\mathsf{compose}$ and the resulting edges
used for anything other than defining path equivalence?)
\par
\textbf{Alternative:} replace $\mathsf{compose}$ with 
either an equivalence function on path pairs,
or a path ``evaluation'' function $\mathsf{value}$
(\textbf{TODO:} need a better name for this),
with path equivalence classes
being the level sets of $\mathsf{value}$.
That's essentially the same as $\mathsf{compose}$,
except we no longer assume the values are also edges in the graph.
Offhand, this seems a lot more intuitive than $\mathsf{compose}$,
adding all these additional, apparently unnecessary, edges to
the graph.
\par
For sets and functions categories, the natural equivalence relation
is that the composed functions corresponding to the paths 
have the same graph relation (map each given domain element to the 
same codomain element. The $\mathsf{value}$ function maps each path
to its equivalence class.
\par
For transportation graphs, and similar, the $\mathsf{value}$ 
function could return a tuple of all path properties relevant to
the problem being solved, eg,  expected travel time, likely fuel 
cost, etc.
\par
(\textbf{Question:} is associativity actually necessary,
even with usual interpretation of $\mathsf{compose}$?
Doesn't really make sense in the context 
of path evaluation/classification.)

\item[Identity]\mbox{}\\
For every vertex $v$, there is a self-loop edge 
$\mathsf{identity}(v)$ whose head and tail
are both $v$.
$\mathsf{compose}$ and $\mathsf{identity}$
must be defined so that  $\mathsf{identity}(v)$ 
``disappears" in any composition with edges 
entering or leaving $v$:
\[ 
\mathsf{compose}(\mathsf{identity}(v),e_0) = e_0 \]
and
\[ \mathsf{compose}(e_1,\mathsf{identity}(v)) = e_1 \]
\par
Again, a lot of room for doubt that this extra structure 
is really necessary.
\par
\textbf{Alternative:} 
extend $\mathsf{compose}$ to take vertices as well as edges,
and return both edges and vertices.
Edge-vertex composition just returns the edge (assuming head/tail match).
Composition of ``inverse'' edges is allowed to return the common vertex,
rather than an artificially added self-loop edge.
\par
If we want to work with paths, either for composition
or more straightforward equivalence definition,
we can change the definition of a path to include the vertices,
so that a single vertex is a path. 
Then $2$ edges can be considered as ``inverses'' if both
$2$-edge paths are path-equivalent to the common vertex.
\end{description}

Figure~\ref{fig:a_completed_digraph} shows the additional
edges needed to make the graph in figure~\ref{fig:a_digraph}
into a category: the identity loops are in blue, first order
compositions red, and second order green.

% Note tkzcd bug: bounding box for diagram includes the control 
% pts of the curved edges! 
\begin{figure}
\centering
\fbox{
\begin{tikzcd}[
row sep=1.2cm, 
column sep=2.5cm,
ampersand replacement = \&,
execute at begin picture={
     \useasboundingbox (-5.15,-3.35) rectangle (4.25,3.4); }
    ]
V_0
\arrow[loop above, blue, crossing over]
%\arrow[drr, bend left=40, "e_{02}" near start]
%\arrow[ddr, bend right=40, "e_{03}"' near start]
\arrow[drr, bend left, "e_{02}" near start]
\arrow[ddr, bend right, "e_{03}"' near start]
\arrow[dr, "{e_{01}}" ] 
\arrow[drr, "e_{12} \circ e_{01}", bend left=10, dashed, red]
\arrow[ddr, "e_{13} \circ e_{01}", bend right=10, dashed, red]
\arrow[loop right, blue, crossing over]
\& 
\& 
\\
\& 
V_1 
\arrow[loop above, blue,crossing over]
\arrow[r, "e_{12}"] 
\arrow[d, "e_{13}"']
\arrow[dr, bend left, "e_{24} \circ e_{12}", dashed, red]
\arrow[dr, bend right, "e_{34} \circ e_{13}"' red, dashed, red]
\& 
V_2 
\arrow[loop right, crossing over, blue]
\arrow[d, "e_{24}"] 
\\
\& 
V_3 
\arrow[loop below, blue,crossing over]
\arrow[r, "e_{34}"']
\&
V_4
\arrow[loop below, blue,crossing over]
\arrow["e_{24} \circ e_{02}" {near end},
from=1-1,to=3-3, red, dashed, bend left=100,]
\arrow["e_{34} \circ e_{03}"' {near end},
from=1-1,to=3-3, red, dashed, bend right=100,]
\arrow["e_{24} \circ e_{12} \circ e_{01}" {near start},
from=1-1,to=3-3, draw=DarkGreen, dashed, bend left=120]
\arrow["e_{34} \circ e_{13} \circ e_{01}"' {near start},
from=1-1,to=3-3, draw=DarkGreen, dashed, bend right=120]
\end{tikzcd}
}
\caption{Completion of fig.~\ref{fig:a_digraph}
to a category}
\label{fig:a_completed_digraph}
\end{figure}


Complete categories like this are rarely drawn,
which seems to follow a propaganda-ish pattern 
I've observed in other graphical languages:
It seems to be common to only draw partial graphs,
where what's omitted is arguably as or more important 
than what's drawn.
I think this is usually an unconscious choice,
but, even so, it has the effect of hiding and distracting 
from the parts of the graphical representation that would
be most open fo questions and doubt.
An example is probabilistic graphical models/bayesian networks
in machine learning, where the key and highly questionable
independence assumptions correspond to the edges that 
\textsl{are not} drawn.

%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{Commuting diagrams}
\label{sec:Commuting_diagrams}

\begin{figure}
\centering
\fbox{
\begin{tikzcd}
[
row sep=1.2cm, 
column sep=2.5cm,
ampersand replacement = \&,
execute at begin picture={
     \useasboundingbox (-3.3,-2.5) rectangle (4.25,3.4); }
    ]
V_0
\arrow[loop above, blue, crossing over]
\arrow[dr, "{e_{01}}" ] 
\arrow[drr, "e_{12} \circ e_{01}"', "e_{02}"  {near start},
bend left]
\arrow[ddr, "e_{13} \circ e_{01}", "e_{03}"' {near start},
bend right]
\& 
\& 
\\
\&
V_1 
\arrow[loop above, blue,crossing over]
\arrow[r, "e_{12}"] 
\arrow[d, "e_{13}"']
\arrow[dr, "e_{24} \circ e_{12}", "e_{34} \circ e_{13}"',
dashed, red]
\& 
V_2 
\arrow[loop right, crossing over, blue]
\arrow[d, "e_{24}"] 
\\
\& 
V_3 
\arrow[loop below, blue,crossing over]
\arrow[r, "e_{34}"']
\& 
V_4
\arrow[loop right, blue, crossing over]
\arrow[
"e_{24} \circ e_{02}",
"e_{34} \circ e_{03}" {near end},
"e_{24} \circ e_{12} \circ e_{01}" {near start},
"e_{34} \circ e_{13} \circ e_{01}"' {near start},
from=1-1,to=3-3, draw=DarkGreen, dashed, bend left=100,]
\end{tikzcd}
}
\caption{Commuting version of fig.~\ref{fig:a_completed_digraph}}
\label{fig:a_commuting_diagram}
\end{figure}

In Figure~\ref{fig:a_completed_digraph}, 
any of the pair of edges with the same head and tail might be
taken to be the same edge, and still satisfy the definition of a
category. 
If all such ``redundant'' pairs are reduced to single edges,
then the diagram is said to \textit{commute}.
This is shown in figure~\ref{fig:a_commuting_diagram}

Commutative diagrams are in some sense the heart of category
theory,
but both ``commutative'' and ``diagram'' are problematic.

I have been unable to find an explanation for the use of
the word ``commute'' to mean ``all displayed paths
with the same head and tail are equivalent''.
This is one of the early symptoms that there's something wrong:
The fact that a key term is used for, as far as I can tell, 
an unrelated concept
from closely related areas of mathematics (eg commutative groups)
is at best, evidence of flawed exposition, if not confused thinking.
To use ``commute'' in the context of the binary $\mathsf{compose}$
operation to mean anything other than $e_0 \circ e_1 = e_1 \circ e_0$
adds pointlessly to the cognitive load of someone new to the subject.

The convention in category theory is to leave out identity loops
and composition edges when drawing diagrams,
which is a symptom that perhaps the identities and compositions
ought not be there.

It worth noting that ``diagram'' is rarely defined in introductory
texts, at least, 
not until long after diagrams have been in use.
And the standard definition---functor from indexing category
to ambient category
(eg \cite[][Definition 1.6.4]{riehl2017})---doesn't reflect how
diagrams are actually drawn and used.

What's drawn is a subgraph, not a category (unless we use
a path-equivalence/identity-free definition of categories).
The functor is essentially irrelevant.
The displayed subgraph is a device for 
reducing the cognitive burden of certain (mental) computations
(like a chess board and pieces);
what's drawn is (should be) the minimum necessary 
to get to the desired result.~\cite{dutilh_novaes_2012}

(\textbf{Question:} is diagram chasing the same thing as proving
a diagram commutes?)

%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}-1}
\levelstay{Mono, epi, iso}
\label{sec:mono_epi_iso}

Two edges are \textit{parallel} is they have the same head and tail.

\begin{figure}
\centering
\begin{tikzcd}
V_0 
\arrow[r, bend left, "f"]
\arrow[r, bend right, "g"']
& V_1 
\arrow[r, "e"]
& V_2 
\end{tikzcd}
if commuting, implies:
\begin{tikzcd}
V_0 
\arrow[r, "f", "g"']
& V_1 
\end{tikzcd}
\caption{Mono edge $e$}
\label{fig:mono}
\end{figure}

\begin{figure}
\centering
\begin{tikzcd}
V_0 \arrow[r, "e"]
& V_1 
\arrow[r, bend left, "f"]
\arrow[r, bend right, "g"']
& V_2 
\end{tikzcd}
if commuting, implies:
\begin{tikzcd}
V_1 
\arrow[r, "f", "g"']
& V_2 
\end{tikzcd}
\caption{Epi edge $e$}
\label{fig:epi}
\end{figure}

\begin{figure}
\centering
\begin{tikzcd}
V_0 
\arrow[loop left, blue, "I_{V_0}"]
\arrow[r, "e", bend left]
\arrow[r, "e^{-1}"', leftarrow, bend right]
& 
V_1 
\arrow[loop right, blue, "I_{V_1}"]
\end{tikzcd}
\caption{Iso edge $e$, if diagram commutes.}
\label{fig:iso}
\end{figure}

\setcounter{currentlevel}{\value{baseSectionLevel}-2}
\levelstay{Standard definition}

An edge $e$ is \textit{mono} (aka a monomorphism)
if, for any parallel edges $f,g$ entering $\mathsf{head}(e)$:
\[
\left( e \circ f = e \circ g \right) \Rightarrow (f = g)
\]

An edge $e$ is \textit{epi} (aka na epimorphism)
if, for any parallel edges $f,g$ departing $\mathsf{head}(e)$:
\[
\left( f \circ e = g \circ e \right) \Rightarrow (f = g)
\]

An edge $e$ is \textit{iso} (aka an isomorphism)
if there exists an edge $e^{-1}$ such that
\[
e^{-1} \circ e = \mathsf{identity}(\mathsf{tail}(e))
\]
and
\[
e \circ e^{-1} = \mathsf{identity}(\mathsf{head}(e))
\]

Mono, epi, and iso are ``abstracted'' 
from one-to-one, onto, and invertible functions.
At this point, it is, at best, not clear that we have gained
anything and we definitely have lost something.
I put quotes around ``abstracted'' because the new concepts are
not simplifications of the originals.
First of all, 
we've broken the modularity of the original concepts:
one-to-one, onto, and invertible can be determined from
the function alone, and the fact that the domain and codomain
somewhat slippery can be handled directly.
(\textbf{TODO:} find the right way to say this.)
Mon, epi, and, particularly, iso depend other edges in the category, 
and details of how $\mathsf{compose}$ is defined.
Specifically, note that,
a function that is one-to-one and onto is
therefore invertible, and vice versa.
On the other hand, all iso edges are both mono and epi,
but an edge that is both mono and epi need not be iso.
For an edge to be iso, it requires the existence of an ``inverse''
edge, that cancels when composed with the original edge 
in either order.

Also, note here another example of needlessly obscure naming.
``one-to-one'' could be ``left invertible'';
``onto'' could be ``right invertible''.
You sometimes see ``left/right cancelable" instead of ``mono/epi'',
but ``cancelable'' wouldn't be the same as ``iso''.



(\textbf{Question:} is this actually desirable?)

\setcounter{currentlevel}{\value{baseSectionLevel}-2}
\levelstay{Alternate (composition-less) definition}

%-----------------------------------------------------------------
%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}}
\levelstay{Topos down}
\label{sec:Topos-down}
 
Topos definition, then define what it depends on, \ldots.
 
%-----------------------------------------------------------------
%-----------------------------------------------------------------
\setcounter{currentlevel}{\value{baseSectionLevel}}
\levelstay{Fusion}
\label{sec:Fusion}

Start from (all of) conventional mathematics,
remove unnecessary details from definitions, theorems, proofs.
Express what remains in graphical category language.
Look for ``graphs'' that match, unifying disparate parts of math.

Problem: you need to learn a lot of conventional math before
you can really start on category theory.

 
%-----------------------------------------------------------------
%-----------------------------------------------------------------
\pagebreak
\appendix
%\part{Appendices}
\import{\texFolder}{typesetting}
%-----------------------------------------------------------------
%\backmatter


%\part{Backmatter}
% un-comment \input and comment \printbibiliography
% to get index, glossary, list of theorems, etc.
%\input{../tex/tail}
\printbibliography[heading=bibintoc, title={References}]
%-----------------------------------------------------------------
\end{document}
