%-----------------------------------------------------------------
%-----------------------------------------------------------------
\begin{plSection}{Why?}
\label{sec:Why?}

\begin{plQuote}
{\citeAuthorYearTitle{AdamekHerrlichStrecker:1990}}
{}
Category theory provides a language 
to describe precisely many similar phenomena that
occur in different mathematical fields. For example,
\begin{enumerate}
  \item  Each finite dimensional vector space is 
  isomorphic to its dual and hence also to its
second dual. The second correspondence is considered 
``natural'', but the first is
not. Category theory allows one to precisely 
make the distinction via the notion
of natural isomorphism.
\item Topological spaces can be defined in many different ways, 
e.g., via open sets, via
closed sets, via neighborhoods, via convergent filters, a
nd via closure operations.
Why do these definitions describe 
``essentially the same'' objects? Category theory
provides an answer via the notion of concrete isomorphism.
\item Initial structures, final structures, 
and factorization structures occur in many different
situations. Category theory allows one to formulate 
and investigate such
concepts with an appropriate degree of generality.
\end{enumerate}

\end{plQuote}

\begin{plQuote}
{\citeAuthorYearTitle{AspertiLongo:1991}}
{}
In addition to its direct relevance to theoretical knowledge and current applications, category theory
is often used as an (implicit) mathematical jargon rather than for its explicit notions and results.
Indeed, category theory may prove useful in construction of a sound, unifying mathematical
environment, one of the purposes of theoretical investigation. As we have all probably experienced, it
is good to know in which ``category'' one is working, i.e., which are the acceptable morphisms and
constructions, and the language of categories may provide a powerful standardization of methods and
language. In other words, many different formalisms and structures may be proposed for what is
essentially the same concept; the categorical language and approach may simplify through abstraction,
display the generality of concepts, and help to formulate uniform definitions. This has been the case,
for example, in the early applications of category theory to algebraic geometry.

\end{plQuote}

\begin{plQuote}
{\citeAuthorYearTitle{Baez:2017:ToposNutshell}}
{}
Okay, you wanna know what a topos is? 
First I'll give you a hand-wavy vague explanation, 
then an actual definition, 
then a few consequences of this definition, 
and then some examples.
\par
I'll warn you: 
it takes a lot of work to learn enough topos theory 
to really use it to solve problems. 
Thus, when you're getting started the main reason to learn 
about it should not be to quickly solve some specific problems, 
but to broaden your horizons and break out of the box 
that traditional mathematics, based on set theory, 
imposes on your thinking.

\end{plQuote}

\begin{plQuote}
{\citeAuthorYearTitle{BarrWells:2020}}
{}
Categories originally arose in mathematics out of the need of a formalism to
describe the passage from one type of mathematical structure to another. A
category in this way represents a kind of mathematics, and may be described
as category as mathematical workspace.
A category is also a mathematical structure. As such, it is a common
generalization of both ordered sets and monoids (the latter are a simple
type of algebraic structure that include transition systems as examples),
and questions motivated by those topics often have interesting answers for
categories. This is category as mathematical structure.
A third point of view is emphasized in this book. A category can be seen
as a structure that formalizes a mathematician's description of a type of
structure. This is the role of category as theory. Formal descriptions in
mathematical logic are traditionally given as formal languages with rules for
forming terms, axioms and equations. Algebraists long ago invented a formalism
based on tuples, the method of signatures and equations, to describe
algebraic structures. In this book, we advocate categories in their role as formal
theories as being in many ways superior to the others just mentioned.
Continuing along the same path, we advocate sketches as definite specifications
for the theories.
\end{plQuote}

\begin{plQuote}
{\citeAuthorYearTitle{FongSpivak:2018:SevenSketches}}
{}
Category theory is becoming a central hub for all of pure mathematics. It is unmatched
in its ability to organize and layer abstractions, to find commonalities between structures
of all sorts, and to facilitate communication between different mathematical
communities.

\end{plQuote}

\begin{plQuote}
{\citeAuthorYearTitle{Geroch:1985:MathPhysics}}
{}
In each area of mathematics 
(e.g. groups, topological spaces) 
there are available many definitions and constructions.
It turns out, however, that there are a number of notions
(e.g. that of a product) that occur naturally 
in various areas of mathematics, with only slight changes from
one area to another.
It is convenient to take advantage of this observation.
Category theory can be described as that branch of mathematics
in which one studies certain definitions in a broader context---without
reference to the particular area 
in which the definition might be applied.
It is the ``mathematics of mathematics''.
\end{plQuote}

\begin{plQuote}
{\citeAuthorYearTitle{LawvereSchanuel:2009:ConceptualMath}}
{}
Since its first introduction over $60$ years ago, the concept of category has been
increasingly employed in all branches of mathematics, especially in studies where the
relationship between different branches is of importance. The categorical ideas arose
originally from the study of a relationship between geometry and algebra; the
fundamental simplicity of these ideas soon made possible their broader application.
\par
The categorical concepts are latent in elementary mathematics; making them more
explicit helps us to go beyond elementary algebra into more advanced mathematical
sciences.
\end{plQuote}

\begin{plQuote}
{\citeAuthorYearTitle{Leinster:2016:BasicCategoryTheory}}
{}
Category theory takes a bird’s eye view of mathematics. From high in the sky,
details become invisible, but we can spot patterns that were impossible to detect
from ground level. How is the lowest common multiple of two numbers
like the direct sum of two vector spaces? What do discrete topological spaces,
free groups, and fields of fractions have in common?We will discover answers
to these and many similar questions, seeing patterns in mathematics that you
may never have seen before.
\par
The most important concept in this book is that of universal property. The
further you go in mathematics, especially pure mathematics, the more universal
properties you will meet. We will spend most of our time studying different
manifestations of this concept.
\par
Like all branches of mathematics, category theory has its own special vocabulary,
which we will meet as we go along. But since the idea of universal
property is so important, I will use this introduction to explain it with no jargon
at all, by means of examples.
\end{plQuote}

\begin{plQuote}
{\citeAuthorYearTitle{MacLane:1998:CategoriesWorking2}}
{}
\ldots On the first level, categories provide
a convenient conceptual language, based on notions of category, 
functor, natural transformation, contravariance, and
functor category.
\ldots Next comes the fundamental idea of an adjoint pair of functors.
This appears in many equivalent forms: that of universal construction,
that of direct and inverse limit, 
and that of a pair of functors with a natural isomorphism between
corresponding sets of arrows. \ldots
The slogan is ``Adjoint functions arise everywhere.''
\par
Alternatively, the fundamental notion of category theory is that
of a monoid---a set with a binary operation of multiplication
that is associative and that has a unit;
a category itself can be regarded as a sort of generalized monoid.
\ldots
\par
Since a category consists of arrows, our subject could be 
described as learning how to live without elements, using arrows
instead.
\end{plQuote}

\begin{plQuote}
{\citeAuthorYearTitle{Riehl:2017:CatTheory}}
{}
Atiyah described mathematics as the
``science of analogy.'' In this vein, the purview
of category theory is mathematical analogy. 
Category theory provides a cross-disciplinary
language for mathematics designed to delineate general phenomena,
which enables the
transfer of ideas from one area of study to another. 
The category-theoretic perspective can
function as a simplifying abstraction, isolating propositions 
that hold for formal reasons
from those whose proofs require techniques particular 
to a given mathematical discipline.
\end{plQuote}

\begin{plQuote}
{\citeAuthorYearTitle{Spivak:2013:CatTheoryForScientists}}
{}
This course is an attempt to extol the virtues of a new branch of mathematics,
called category theory, which was invented for powerful communication of ideas between
different fields and subfields within mathematics. By powerful communication of ideas I
actually mean something precise. Different branches of mathematics can be formalized
into categories. These categories can then be connected together by functors. And the
sense in which these functors provide powerful communication of ideas is that facts and
theorems proven in one category can be transferred through a connecting functor to
yield proofs of analogous theorems in another category. A functor is like a conductor of
mathematical truth.
\par
I believe that the language and toolset of category theory can be useful throughout
science. We build scientific understanding by developing models, and category theory is
the study of basic conceptual building blocks and how they cleanly fit together to make
such models. Certain structures and conceptual frameworks show up again and again in
our understanding of reality. No one would dispute that vector spaces are ubiquitous.
But so are hierarchies, symmetries, actions of agents on objects, data models, global
behavior emerging as the aggregate of local behavior, self-similarity, and the effect of
methodological context.
\par
% Some ideas are so common that our use of them goes virtually undetected, such as set theoretic
% intersections. For example, when we speak of a material that is both lightweight
% and ductile, we are intersecting two sets. But what is the use of even mentioning this
% set-theoretic fact? The answer is that when we formalize our ideas, our understanding
% is almost always clarified. Our ability to communicate with others is enhanced, and the
% possibility for developing new insights expands. And if we are ever to get to the point
% that we can input our ideas into computers, we will need to be able to formalize these
% ideas first.
$\cdots$
\par
It is my hope that this course will offer scientists a new vocabulary in which to think
and communicate, and a new pipeline to the vast array of theorems that exist and are
considered immensely powerful within mathematics. These theorems have not made their
way out into the world of science, but they are directly applicable there. Hierarchies are
partial orders, symmetries are group elements, data models are categories, agent actions
are monoid actions, local-to-global principles are sheaves, self-similarity is modeled by
operads, context can be modeled by monads.
\end{plQuote}

An alternative to first order logic, sets, 
and functions as a foundation for all
mathematics~\cite{Feferman:1977:CategoricalFoundations},  
particularly topos theory.

\end{plSection}%{Why?}
%-----------------------------------------------------------------
%-----------------------------------------------------------------
\begin{plSection}{Doubts}
\label{sec:Doubts}

Possible problems with category theory that should be examined.

%-----------------------------------------------------------------
\begin{plSection}{Hype}
\label{sec:Hype}

\begin{plQuote}
{\citeAuthorYearTitle{Cheng:2020:Latest}.}
{}
Why are men in charge? 
After years in the male-dominated field of mathematics 
and in the female-dominated field of art, 
Eugenia Cheng has heard the question many times. 
In x + y, Cheng argues that her mathematical 
specialty---category theory---reveals why. 
Category theory deals more with context, relationships, 
and nuanced versions of equality than 
with intrinsic characteristics. 
Category theory also emphasizes dimensionality: 
much as a cube can cast a square or diamond shadow, 
depending on your perspective, 
so too [sic] do gender politics appear to change 
with how we examine them. 
% Because society often rewards traits 
% that it associates with males, such as competitiveness, 
% we treat the problems those traits can create as male. 
% But putting competitive women in charge will leave 
% many unjust relationships in place. 
% If we want real change, 
% we need to transform the contexts in which we all exist, 
% and not simply who we think we are.
\end{plQuote}

\begin{plQuote}
{Somewhat confused anonymous article in
Quanta and WIRED 
magazines~\cite{Hartnett:2019:Lurie,Quanta:2019:Lurie}:}
{}
The most prominent figure in this community is Jacob Lurie. 
\\
$\cdots$
\\
Lurie’s ideas are sweeping on a scale rarely seen in any field. 
Through his books, which span thousands of dense, technical pages, 
he has constructed a strikingly different way to understand some 
of the most essential concepts in math by moving 
beyond the equal sign. 
``I just think he felt this was the correct way to think 
about mathematics,'' said Michael Hopkins, a mathematician 
at Harvard and Lurie’s graduate school adviser.
\\
Lurie published his first book, Higher Topos Theory, in $2009$. 
The $944$-page volume serves as a manual for how 
to interpret established areas of mathematics 
in the new language of ``infinity categories.'' 
In the years since, Lurie’s ideas have moved 
into an increasingly wide range of mathematical disciplines. 
Many mathematicians view them as indispensable 
to the future of the field. ``No one goes back once they’ve learned 
infinity categories,'' said John Francis of Northwestern University.
\\
$\cdots$
\\
Yet the spread of infinity categories has also revealed 
the growing pains that a venerable field 
like mathematics undergoes whenever it tries 
to absorb a big new idea, especially an idea 
that challenges the meaning of its most important concept. 
``There’s an appropriate level of conservativity 
in the mathematics community,'' 
said Clark Barwick of the University of Edinburgh. 
``I just don’t think you can expect 
any population of mathematicians to accept any tool 
from anywhere very quickly without giving them convincing reasons 
to think about it.''
\\
Although many mathematicians have embraced infinity categories, 
relatively few have read Lurie’s long, highly abstract texts 
in their entirety. As a result, some of the work 
based on his ideas is less rigorous than is typical in mathematics.
\\
``I’ve had people say, ‘It’s in Lurie somewhere,’'' 
said Inna Zakharevich, a mathematician at Cornell University. 
``And I say, ‘Really? You’re referencing $8,000$ pages of text.’ 
That’s not a reference, it’s an appeal to authority.''
% \par
% Mathematicians are still grappling 
% with both the magnitude of Lurie’s ideas 
% and the unique way in which they were introduced. 
% They’re distilling and repackaging his presentation 
% of infinity categories to make them accessible 
% to more mathematicians. They are performing, 
% in a sense, the essential work of governance 
% that must follow any revolution, translating a transformative text 
% into day-to-day law. 
% In doing so, they are building a future for mathematics founded 
% not on equality, but on equivalence.
\end{plQuote}

Much of what's written about category theory feels like marketing.
I read many vague claims about its value
(or perhaps I just don't understand the more specific claims).
Then I pick up some introductory text,
and after ${\sim}500$ pages of progressively less and less 
intuitive definitions, and unconvincing examples in category Sets,
or maybe category Monoids,
but still no actual evidence of anything that wouldn't have been
easier and simpler in the original context.

When people try to give examples of applications outside the
math-structures-and-structure-preserving-functions context,
it seems appears that that  they are really just using directed
(multi)graphs, if not just relations (eg Cheng~\cite{Cheng:2020:Latest}).
I haven't yet found any use of the relatively obscure category 
constructs.

A possible symptom that's something wrong:
Category theory, which originated in $1940$s,
was still, in $2013$, $60+$ years, later being described in terms like:
``This course is an attempt to extol the virtues of a new branch of mathematics,
called category theory, which was invented for powerful communication of ideas between
different fields and subfields within mathematics.''~\cite{Spivak:2013:CatTheoryForScientists}.
It doesn't seem like such assertions would be necessary,
if it really were the 'right' way to unify 
and illuminate all of mathematics.

\end{plSection}%{Hype}
%-----------------------------------------------------------------
\begin{plSection}{Shaky foundations}
\label{sec:Shaky-foundations}

\begin{plQuote}
{\citeAuthorYearTitle{Feferman:1977:CategoricalFoundations}}
{}
The point is simply that when explaining the general notion of
structure and of particular kinds of structures such as groups, rings,
categories, etc. we implicitly presume as understood the ideas of
operation and collection; e.g. we say that a group consists of a collection
of a objects together with a binary operation satisfying such and
such conditions. Next, when explaining the notion of homomorphism
for groups or functor for categories, etc., we must again understand the
concept of operation. Then to follow category theory beyond the basic
definitions, we must deal with questions of completeness, which are
formulated in terms of collections of morphisms. Further· to verify
completeness in concrete categories, we must be able to form the
operation of Cartesian product over collections of its structures. Thus
at each step we must make use of the unstructured notions of operation
and collection to explain the structural notions to be studied. The
logical and psychological priority if not primacy of the notions of
operation and collection is thus evident.
\par
It follows that a theory whose objects are supposed to be highly
structured and which does not explicitly reveal assumptions about
operations and collections cannot claim to constitute a foundation for
mathematics, simply because those assumptions are unexamined. It is
evidently begging the question to treat collections (and operations
between them) as a category which is supposed to be one of the objects
of the universe of the theory to be formulated.
\par
The foundations of mathematics must still be pursued in a direct
examination of the notions of operation and collection. There are at
present only two (more or less) coherent and comprehensive approaches
to these, based respectively on the Platonist and the constructivist
viewpoints. Only the first of these has been fully elaborated,
taking as basis the conception of sets in the cumulative hierarchy. It is
distinctive of this approach that it is extensional, i.e., collections are
considered independent of any means of definition. Further, operations
are identified with their graphs.
\end{plQuote}

Note: Feferman's critique still considered valid, unanswered,
$45+$ years later:

\begin{plQuote}
{\citeAuthorYearTitle{Landry:2013:FefermanResponse}}
{}
Feferman’s 1977 paper, ``Categorical Foundations and Foundations
of Category Theory'', has been appealed to often to argue 
that category theory cannot stand
on its own as a structuralist foundation for mathematics
(Bell, 1981; Hellman, 2003).
Others have argued that a category-theoretic structuralist 
foundation is still possible by
claiming that Feferman misses his mark 
(Landry, 2006; Marquis, 2006, 2009; McLarty,
2004, 2005). 
In any case, Feferman (1977), had become, and remains still, 
the litmus test for arguments for and against category-theoretic
 structuralist foundations.
\end{plQuote}

\end{plSection}%{Shaky foundations}
%-----------------------------------------------------------------
\begin{plSection}{Complexity}
\label{sec:Complexity}

A problem for novices is depth of definition, theorem,
and concept dependence.

The constructs do not feel natural, in themselves, 
to the uninitiated.
Examples: product/sum, epic/monic morphisms, {\ldots}.

The general feel is like a student who manages to solve a problem
by quasi-random search over possible next steps,
stumbling their way to the desired result,
without any coherent overview or intuition.

A telltale symptom of bad math is when the premise of a theorem
(or the necessary definition) is so complicated and arbitrary,
and difficult to verify in any practical setting,
that it seems more reasonable to just assume the conclusion,
and skip the intervening nonsense.
(eg many central limit theorems are like this).

Is part of the attraction due to the (unnecessary?)
complexity providing opportunities for lots of
least-publishable-unit 
theorem-credits?~\cite{JaffeQuinn:1993:TheoreticalMath,Thurston:1994:Proof}

\textbf{Question:} Are there reasonable quantitative measures
of the complexity of a theory/subject/textbook?
For example, something computed from the DAG of
definition/theorem dependencies?
Anything in software complexity measures that would apply?

\end{plSection}%{Complexity}
%-----------------------------------------------------------------
\begin{plSection}{Is an arrow more general than a function?}
\label{sec:arrow-more-general}

\begin{plQuote}
{\citeAuthorYearTitle[p~247]{EilenberMacLane:1945:Equivalences},\\
quoted in \\
\citeAuthorYearTitle[p~3]{LandryMarquis:2005:CatTheoryContext}}
{}
\ldots the whole concept of a category is essentially 
an auxiliary
one; our basic concepts are essentially those of a functor and of
a natural transformation {\ldots}. 
The idea of a category is required
only by the precept that every function should have a definite
class as domain and a definite class as range, for the categories
are provided as the domains and ranges of functors. Thus one
could drop the category concept altogether and adopt an even
more intuitive standpoint, in which a functor such as ‘hom’ is
not defined over the category of ‘all’ groups, 
but for each particular
pair of groups which may be given. The standpoint would
suffice for the applications, inasmuch as none of our developments
will involve elaborate constructions on the categories
themselves.
\end{plQuote}

Do functions/functors really need definite (co)domains?

There's a fair amount of arbitrariness 
to the domain and codomain of a function.

Any function that takes elements of a set $\Set{X}$
and returns elements of a set $\Set{Y}$
is, or is intimately connected to, 
a function that takes subsets of $\Set{X}$ and returns
subsets of $\Set{Y}$.

For any function, we can expand the domain, by considering partial
functions. 
Partial functions may be necessary in a computable context,
since we don't in general know if a given function will
halt for all elements of the domain.
The closer we get to real computation, the more we may need to
handle exceptional return values, ie, replace the natural
codomain by its union with a set of error/exception objects.

Category theory abstracts functions between sets to
arrows (maps, morphisms) between objects,
with the co/domain objects part of the identity of the arrow.

Given a (procedural) function,
we can choose any superset of the range as the codomain.
We can also restrict a function to any subset of the domain,
and it may be important to know that one function is a simple 
restriction of another---is there a reasonable way to do this
for arrows?

\end{plSection}%{Is an arrow more general than a function?}
%-----------------------------------------------------------------
\begin{plSection}{Modularity breaking}
\label{sec:Modularity_breaking}

Modularity a key design principle for any system: physical, 
software, or formal.

One of the issues I have with category theory
may be a tendency to break the modularity of the constructs it is
``abstracting''.

One example is, again, functions vs arrows.
As mentioned in section~\ref{sec:arrow-more-general},
the association of a function and its domain, and, particularly,
codomain is, in practice, pretty loose.
Modifying a function by restricting, extending, or otherwise
modifying the domain and/or codomain is common.
Although it's not usually clearly stated, 
I think most operate as though there is a common entity
that's shared by all these essentially trivial variations on the
same function.
As far as I know, category theory does not provide anything similar:
no way to construct a new arrow by modifying the domain
and codomain of the original, while maintaining other properties.

More generally, I think I am beginning to see a pattern where
constructs that are modular in a sets-and-functions context,
in the sense that they only depend on an individual function or
set, or perhaps a few such, require global information about
the whole category.
For example, whether a function is one-to-one or onto
can be determined from the function in isolation,
or, at most, using the domain and codomain.
Determining whether an arrow is monic or epic requires
considering all other arrows that share the (co)domain,
and what the \compose operation does in those cases.

I imagine a counter-argument along the lines of:
moving only the necessary, minimal semantics out of the ``atomic''
inner component entities, 
into the surrounding structure (the category) allows the same 
outer structure to be used
with other atomic entities, and hopefully, significant results
can then be obtained, independent of the inner components.
(I'm almost surely not doing real justice to this kind of argument.)
In any case, I think it's wrong.

I suspect there's a useful analogy to data structure design.

At one end of a spectrum, code is built out of conceptually 
``large'' objects, encapsulating considerable state and
behavior. In any particular context, only a limited interface
is used, depending on a small subset of the state and behavior,
with the code otherwise independent of the hidden functionality.
When objects like this are held in collections, those collections
tend to be simple, eg lists, with almost no assumptions
about what the elements of the list are.
This kind of code is more common in languages developed 
after $1990$.

At the other end of the spectrum are systems where the semantics
are diffused from the elements into the surrounding collection.
In such systems, the elements are typically restricted 
to a few primitive types (eg integers, floats, strings).
Such systems go back to the $1960$s, 
and, although still in wide use,
plague those who must deal with them (as I can attest from personal
experience).
Such systems result in bug-ridden, inefficient, 
inflexible, brittle code.

(\textbf{TODO:} More complete examples? 
How much detail is actually useful to anybody?)

One example is Fortran. The only data structure is the array.
The meaning of any array can only be determined examining every
place in the code where that array might be touched.

Another is relational databases. The semantics is determined
by which tables are joined to which on what columns.
It is practically impossible to add functionality to a system
built on relational databases without starting from scratch.

R, Matlab (array/relation languages with some modern features
patched on) vs Python.

\end{plSection}%{Modularity breaking}
%-----------------------------------------------------------------
\begin{plSection}{Graphical languages}
\label{sec:Graphical-languages}

Idea that won't die. 
Not completely without value, 
but very limited in terms of the complexity of ideas that can be
expressed.

Another problem is that graphical languages don't lend themselves
to ``computation''
in the same way that text-based languages do,
particularly math notation.~\cite{DutilhNovaes:2012:FormalLanguages}

\end{plSection}%{Graphical languages}
%-----------------------------------------------------------------
\end{plSection}%{Doubts}
%-----------------------------------------------------------------
%-----------------------------------------------------------------
\begin{plSection}{Key ideas in category/topos theory}
\label{sec:Key-ideas}

Some references:
\begin{itemize}
\item \citeAuthorYearTitle{AdamekHerrlichStrecker:1990}
\item \citeAuthorYearTitle{AspertiLongo:1991}
\item \citeAuthorYearTitle{Awodey:2010}
\item \citeAuthorYearTitle{BarrWells:2020}
\item \citeAuthorYearTitle{Geroch:1985:MathPhysics}
\item \citeAuthorYearTitle{Goldblatt:1984:Topoi}
\item \citeAuthorYearTitle{Hillman:2001:CatPrimer}
\item \citeAuthorYearTitle{LawvereSchanuel:2009:ConceptualMath}
\item \citeAuthorYearTitle{Leinster:2016:BasicCategoryTheory}
\item \citeAuthorYearTitle{MacLane:1998:CategoriesWorking2}
\item \citeAuthorYearTitle{Perrone:2019:CatTheory}
\item \citeAuthorYearTitle{Riehl:2017:CatTheory}
\item \citeAuthorYearTitle{Spivak:2013:CatTheoryForScientists}
\item \citeAuthorYearTitle{VanOosten:2002:CatTheory}
\end{itemize}

Things above authors claim are important or valuable;
things that ought to be understood,
and ought to be presentable in a natural, intuitive way.
Ordered by approximately mean rank in the references:

\begin{enumerate}
  
  \item Topos, elementary topos: 
  category ``essentially the same as \textbf{Set}''
  \item subobject (classifier)
  \item Cartesian closed category
  \item initial, terminal object
  \item product, sum/coproduct, exponential, meet, join
  \item monic/epic morphism
  \item split/retraction,/isomorphism
  \item duality/opposite
  \item equalizers
  \item limits
  \item pullback/pushout
  \item completeness
  \item universal (mapping) property
  \item adjointness
\end{enumerate}

\end{plSection}%{Key ideas in category/topos theory}
%-----------------------------------------------------------------
%-----------------------------------------------------------------
\begin{plSection}{Example categories}
\label{sec:Example-categories}

One question to be examined here is: are there any meaningful
categories that aren't some version of a collection of sets
and a collection of functions between? 
By ``meaningful'', I mean that the key ideas 
in section~\ref{sec:Key-ideas} apply
and are useful in some way.
And, in any of the cases, 
does categorical language help or hurt?

\begin{itemize}
  \item Sets of sets and sets of functions between them.
Sometimes relations rather than functions.
More specifically, mathematical structures and
structure-preserving functions between them.

  \item Monoids, groups, etc. \par
  Each monoid category has a single object which can be taken as
  corresponding to the set of elements. The arrows correspond to 
  individual elements, or to the functions obtained from partial
  evaluation of the monoid operation: 
  $f_A(\_)= \comop (A,\_) = A \comop \_$.\par
  One obvious problem with this is that it excludes about half of
  the group-like, one set, one operation structures~\cite{wiki:Magma}: 
  the ones without identity. 
  An example where identity arrows are a problem. \par
  Also, seems clear that many of the key categorical constructs
  don't apply, raising even more questions about whether there's
  any value.
  
  \item Pre-ordered sets, partially ordered sets, including
  inclusion ordering in topology.
  
  
  \item ``Discrete'' categories. Object are elements of a set; 
  only arrows are identities, one per element. 
  (Another example where identity arrows are problematic.)
  Almost surely of no value.
  
  \item Completion of arbitrary directed graph; 
  almost surely of no value, at least on its own.
  This includes things commonly represented as directed graphs,
  without any additional categorical structure, 
  like ontologies~\cite{Spivak:2013:CatTheoryForScientists},
  state transition diagrams, dependency graphs, etc.
  Do categorical completion and constructs help with anything?
  
  \item Types signatures in ``functional'' programming.
  
  \item Categories of arrows, categories, functors, etc.
  Is there anything here beyond certain sets and functions between
  them?
  \item Slice categories~\cite[sec~2.6.10]{BarrWells:2020}
\end{itemize}
\end{plSection}%{Example categories}
%-----------------------------------------------------------------
%-----------------------------------------------------------------
\begin{plSection}{Bottom up}
\label{sec:Bottom-up}

Start from directed (multi)graph~\cite{wiki:DirectedGraph},
define key categorical ideas (\cref{sec:Key-ideas}) 
in those terms.

Claim: categorical constructs are 
pretty much impossible to motivate in this context.
(Like starting from matrices rather than linear functions.)

Look for more natural, simpler alternative definitions?

In this section, I'm going to use graph terminology,
eg, ``vertex'' and ''edge'', rather than ``object'' and ``arrow'',
but I will follow the category theory convention of
upper case letters for vertices/objects and lower case for
edges/arrows.

%-----------------------------------------------------------------
\begin{plSection}{Directed graph}
\label{sec:Directed_graph}

(\textbf{Question:}
 any value is thinking about undirected graphs?
 Simplicial complexes?)

\begin{plDefinition}{Directed graph}{}
A \ding{directed (multi)graph} (aka \ding{digraph}) is
an ordered pair $G=\left( \Set{V}, \Set{E} \right)$,
where $\Set{V}$ is a set of \ding[vertex]{vertices}, 
$\Set{E}$ a set of \ding[edge]{edges}, ordered pairs of vertices.
$V_0 = \tail(e)$ and $V_1 = \head(e)$
for edge $e = \left[ V_0, V_1 \right]$.
\end{plDefinition}

In (computational) applications, $\Set{V}$ and $\Set{E}$ 
are finite, perhaps unbounded finite,
but, in general, they need not be.

It's common to assume 
\begin{enumerate}
\item there is at most one edge
in a graph connecting any $2$ vertices.\par
\item the vertices in an edge must be 
distinct (no loop edges).
\end{enumerate}
(\textbf{Question:} does ``ordered pair'' imply uniqueness?
In other words, can we have multiple distinct copies of
 $\left(A,B\right)$, pairing the same elements $A$ and $B$?
 If we use one of the primitive set theory ``implementations'',
 then there is only one $\left(A,B\right)$ 
 for given $A$ and $B$.)

A graph may be called a \ding{multigraph} when $1$ is
not assumed.

In a context where loops are allowed,
a graph with no loops may be called 
\ding[simple graph]{simple}.

(\textbf{Question:} 
Digraph special case of (oriented) simplicial complex.
What's the difference between a simplicial complex 
and a hypergraph?)

A \ding{path} is a sequence of edges where the head of each
edge matches the tail of the following edge, if there is one.

An \ding{directed acyclic graph} (aka DAG) has no paths
connecting a vertex to itself.

A directed graph is 
\ding[connected graph]{(strongly) connected} 
if there is a path
from any vertex to any other (weakly if there is path
ignoring direction.

(\textbf:{TODO:} straighten out \ding{path} vs \ding{walk} vs
\ding{trail}; directed vs undirected; sequence of alternating
vertices and edges, starting and beginning with a vertex.)

A \ding{root} vertex (aka source) has no entering edges.

A \ding{leaf} vertex (aka sink) has no departing edges.

A \ding{tree} is a directed graph with one root, 
where all vertices have at most entering edge.

(Mesh) \ding[dual graph]{dual} of a graph interchanges the roles of edges 
and vertices, resulting in a hypergraph where every dual vertex
has exactly $2$ edges. 
(\textbf{Question:} orientation/direction 
of dual edges?~\cite{Rusnak:2012:OrientedHyperGraphs})
(Other notion of dual of planar graph interchanges 
vertices and ``faces'',
orientation from $90^{\comop}$ 
turn of primal edge.~\cite{wiki:DualGraph})

\begin{plDiagram}[nofloat]
{A directed (acyclic) graph}
{digraph}
\centering
\begin{tikzcd}[
row sep=1.2cm, 
column sep=2.5cm,
ampersand replacement = \&,
%execute at begin picture={
%     \useasboundingbox (-5.15,-3.35) rectangle (4.25,3.4); }
    ]
V_0
\arrow[drr, "e_{02}", bend left]
\arrow[ddr, "e_{03}"', bend right]
\arrow[dr, "{e_{01}}"] 
\& 
\& 
\\
\& 
V_1 
\arrow[r, "e_{12}"] 
\arrow[d, "e_{13}"']
\& 
V_2 
\arrow[d, "e_{24}"] 
\\
\& 
V_3 
\arrow[r, "e_{34}"']
\& V_4
\end{tikzcd}
\end{plDiagram}

An example in \cref{diagram:digraph}:
$V_0$ is the only root; $V_4$ is the only leaf;
the graph is simple, connected, and acyclic.

Applications of directed graphs:~\cite{CormenLeisersonRivestStein:2009:Algorithms}
\begin{itemize}
  \item Transportation networks
  \item Shortest path
  \item Predict travel time
  \item Maximum flow
  \item network design/optimization
  \item connected components
  \item spanning trees
  \item dependencies among modules, tasks, definitions/theorems
  \item finite state machines, state-transition diagrams
  \item continuation-passing code (no automatic return to caller)
  \item graph layout (mapping vertices to $2$d points).
\end{itemize}
\end{plSection}
%-----------------------------------------------------------------
\begin{plSection}{Category}
\label{sec:Category_from_digraph}

%-----------------------------------------------------------------
\begin{plSection}{Category (standard)}

\begin{plDefinition}{Category (standard)}{}
A \ding{category} is a directed (multi) graph 
together with two functions that impose constraints
on the graph:
\begin{description}
\item[\compose \textrm{\textup{(infix: $\comop$)}}]\mbox{}\\
At least $2$ ways to think about this. 
More common way first, better (?) way second.\\
The usual way this is posed is for pairs of connected edges:
Whenever $\tail(e0) = \head(e_1)$,
then
\[ \compose(e_0,e_1) = e_0 \comop e_1 = e_{10} \]
is defined
for some $e_{10}$ among the edges of the graph,
with $\tail(e_{10}) = \tail(e_1)$
and $\head(e_{10}) = \head(e_0)$.
(Note the potential for confusion 
in the ordering of the arguments to \compose;
general idea is that $e_1$ is traversed/applied first,
then $e_0$.) \\
In addition, \compose is required to be associative:
\begin{align*}
\compose(\compose(e_0,e_1),e_2) 
&
= \compose(e_0,\compose(e_1,e_2))
\\
&
= \compose(e_0,e_1,e_2)
\end{align*}
\\
An alternative is define the domain of \compose
to be the graph's paths. 
Then, for all paths $p$ in the graph,
there exists some edge $e$ in the graph
with 
\begin{equation*}
\compose(p) = e
\end{equation*} 
such that 
$p$ and $e$ have the same head and tail.
Associativity here means that if we partially reduce a path
by applying \compose to a sub-path,
and then \compose the partially reduced path,
we get the same edge as composing the whole path.
\\
Either way we define \compose (no reason not to do both
simultaneously), it is clearly (to me) not a natural construct
for directed graphs: for every path, there is also 
a single edge directly connecting its tail to its head.
And associativity imposes strong constraints on which of the possibly
many such single edges can be chosen as the value of \compose.
\\
I don't know of any non-categorical applications of directed graphs
for which this makes sense.
Moreover, it's not clear that any of this is really necessary.
\\
\item[\identity]\mbox{}\\
For every vertex $V$, there is a self-loop edge 
$\identity(V)$ whose head and tail
are both $V$.
\compose and \identity
must be defined so that  $\identity(v)$ 
``disappears'' in any composition with edges 
entering or leaving $V$:
\[ 
\compose(\identity(V),e_0) = e_0 \]
and
\[ \compose(e_1,\identity(V)) = e_1 \]
\\
Again, a lot of room for doubt that this extra structure 
is really necessary.
\\
For example, we could extend \compose 
to take vertices as well as edges,
and return both edges and vertices.
Edge-vertex composition just returns the edge (assuming head/tail match).
Composition of ``inverse'' edges is allowed to return the common vertex,
rather than an artificially added self-loop edge.
\end{description}
\end{plDefinition}

\Cref{diagram:aCompletedDigraph} shows the additional
edges needed to make the graph in \cref{diagram:digraph}
into a category: the identity loops are in blue, first order
compositions red, and second order green.

% Note tkzcd bug: bounding box for diagram includes the control 
% pts of the curved edges! 
\begin{plDiagram}
{Completion of \cref{diagram:digraph} to a category}
{aCompletedDigraph}
\centering
%\fbox{
\begin{tikzcd}[
row sep=1.2cm, 
column sep=2.5cm,
ampersand replacement = \&,
execute at begin picture={
     \useasboundingbox (-5.15,-3.35) rectangle (4.25,3.4); }
    ]
V_0
\arrow[loop left, blue, crossing over]
%\arrow[drr, bend left=40, "e_{02}" near start]
%\arrow[ddr, bend right=40, "e_{03}"' near start]
\arrow[drr, bend left, "e_{02}" near start]
\arrow[ddr, bend right, "e_{03}"' near start]
\arrow[dr, "{e_{01}}" ] 
\arrow[drr, "e_{12} \comop e_{01}", bend left=10, dashed, red]
\arrow[ddr, "e_{13} \comop e_{01}", bend right=10, dashed, red]
\& 
\& 
\\
\& 
V_1 
\arrow[loop above, blue,crossing over]
\arrow[r, "e_{12}"] 
\arrow[d, "e_{13}"']
\arrow[dr, bend left, "e_{24} \comop e_{12}", dashed, red]
\arrow[dr, bend right, "e_{34} \comop e_{13}"' , dashed, red]
\& 
V_2 
\arrow[loop right, crossing over, blue]
\arrow[d, "e_{24}"] 
\\
\& 
V_3 
\arrow[loop below, blue,crossing over]
\arrow[r, "e_{34}"']
\&
V_4
\arrow[loop right, blue,crossing over]
\arrow["e_{24} \comop e_{02}" {near end},
from=1-1,to=3-3, red, dashed, bend left=100,]
\arrow["e_{34} \comop e_{03}"' {near end},
from=1-1,to=3-3, red, dashed, bend right=100,]
\arrow["e_{24} \comop e_{12} \comop e_{01}" {near start},
from=1-1,to=3-3, draw=DarkGreen, dashed, bend left=120]
\arrow["e_{34} \comop e_{13} \comop e_{01}"' {near start},
from=1-1,to=3-3, draw=DarkGreen, dashed, bend right=120]
\end{tikzcd}
%}
\end{plDiagram}

Complete categories like this are rarely drawn,
which seems to follow a propaganda-ish pattern 
I've observed in other graphical languages:
It is common to only draw partial graphs,
where what's omitted is arguably as or more important 
than what's drawn.
I think this is usually an unconscious choice,
but, even so, it has the effect of hiding and distracting 
from the parts of the graphical representation that would
be most open fo questions and doubt.
An example is probabilistic graphical models/bayesian networks
in machine learning, where highly questionable
independence assumptions correspond to edges that 
are \textsl{not} drawn.
\end{plSection}
%-----------------------------------------------------------------
\end{plSection}
%-----------------------------------------------------------------
\begin{plSection}{Functor}
\label{sec:functor}

For all the fuss, there doesn't seem to be much to functors:
A \ding{functor} is simply a structure-preserving function
between categories (or kategories), in the usual sense:
it can be applied any entity 
making up the structure,
and it ``commutes'' or ``distributes'' appropriately
over the structure functions.

\begin{plDefinition}{Structure-preserving function between directed
graphs\\ (aka directed graph homomorphism)}{}
$f:G_0 \rightarrow G_1$ is a structure-preserving function
between directed graphs, if and only if:
\begin{align*}
  & f(\vertices(G_0)) \, \subseteq \, \vertices(G_1) \\
  & f(\edges(G_0)) \, \subseteq \, \edges(G_1) \\
  & \forall e \in \edges(G_0) 
  \begin{cases}
  & f(\head(e)) = \head(f(e)) \\
  & f(\tail(e)) = \tail(f(e))
  \end{cases}
\end{align*}
We apply $f$ to paths in the obvious way.
\end{plDefinition}

\begin{plDefinition}{Functor}{}
A \ding{functor} $F:C_0 \rightarrow C_1$ is 
a structure-preserving function
between categories, which requires that is a structure-preserving 
function between directed graphs, and:
\begin{align*}
  F(\compose_{C_0}(e_0,e_1)) & = \compose_{C_1}(F(e_0),F(e_1))\\
  F(\identity_{C_0}(V_0)) & = \identity_{C_1}(F(V_0)
\end{align*}
  (Subscripts on \compose and \identity 
  are usually dropped, but we might 
  encounter two categories that have the same vertices and edges,
  but differ in the definition of the two functions.)
\end{plDefinition}

\end{plSection}
%-----------------------------------------------------------------
\begin{plSection}{Diagram}
\label{sec:Diagram}

Diagrams are in some sense the core of category theory;
they are, however, defined ambiguously, incorrectly, 
or not at all, in the references I've seen:

\begin{plDefinition}
{Diagram (pictorial)\\
\textmd{
\citeAuthorYear{Geroch:1985:MathPhysics,Goldblatt:1984:Topoi,
Hillman:2001:CatPrimer}
}}
{diagram_pictorial}
``By \ding{diagram} we mean any collection of objects
along with a collection of morphisms between various of those
objects. (E.g., a diagram is what is pictured.)''~\cite{Geroch:1985:MathPhysics} 
\par
This is wrong, because it doesn't deal with the common
case of multiple vertices and edges with the same labels.
\end{plDefinition}

\begin{plDefinition}{Diagram (graph to graph)
\textmd{
\citeAuthorYear{BarrWells:2020}
}}
{}
Let $I$ and $G$ be {[directed) graphs]}.
A \ding{diagram} in $G$ of shape $I$
is a graph homomorphism $D : I \rightarrow G$ of graphs.
\end{plDefinition}

\begin{plDefinition}{Diagram (graph to category)
\textmd{
\citeAuthorYear{AspertiLongo:1991}
}}
{}
Let $I$ be a directed graph
 and $C$ be a category.
A \ding{diagram} in $G$ of shape $I$
is a graph homomorphism $D : I \rightarrow C$ of graphs.
\end{plDefinition}

\begin{plDefinition}{Diagram (category to category)
 \textmd{(broken)}}
{}
\label{def:diagram_cat_to_cat}
Let $I$ and $A$ be categories.
A \ding{diagram} is a functor $D : I \rightarrow A$.
$I$ is the \ding{shape} (aka \ding{scheme},
\ding{index category}) of the diagram $D$.\\
Sometimes $I$ is required to a small category
(sets vs classes crap).\\
This is often introduced in the context of limits,
after $100$s of pages
with multiple diagrams on each:
\begin{itemize}
\item \citeAuthorYear[p$193/524$]{AdamekHerrlichStrecker:1990}
\item \citeAuthorYear[p$101/311$]{Awodey:2010}
\item \citeAuthorYear[p$118/183$]{Leinster:2016:BasicCategoryTheory}
(commutative diagrams introduced on p$11$!)
\item \citeAuthorYear[p$38/240$]{Riehl:2017:CatTheory}
 (earlier than most),
\item \citeAuthorYear[p$180/267$]{Spivak:2013:CatTheoryForScientists}
\item \citeAuthorYear[p$16/86$]{VanOosten:2002:CatTheory} (also relatively early)
\end{itemize}
These definitions are clearly \textbf{wrong}.
What's drawn is not a category.
Drawing a category would make impossible the primary use of diagrams,
that is to aid in reasoning
about the equivalences of path in the diagram (``commuting'').
\end{plDefinition}

\citeAuthorYear[p$18/181$]{Perrone:2019:CatTheory}
gives ``an informal (but consistent) definition'' early,
followed by the incorrect category to
category definition \ref{def:diagram_cat_to_cat}, still relatively 
early~\cite[p$53/181$]{Perrone:2019:CatTheory}:
\begin{plDefinition}{Diagram (informal but consistent)\\
 \textmd{{\citeAuthorYear[Definition 1.1.33]{Perrone:2019:CatTheory}}})}
{diagram_perrone}
``A diagram in a category $C$ is a directed (multi-)graph formed 
out of objects and arrows of $C$ such that:
\begin{itemize}
\item Each object and morphism 
may appear more than once in the diagram;
\item Between any two objects 
there may be also more than one morphism;
\item For each object X in the diagram, 
the identity is implicitly present in the diagram (but generally
not drawn);
\item For each {[pair of]} composable edges 
(arrows) $f : X \rightarrow Y$ and $g : Y \rightarrow Z$
which are appearing head-to-tail
in the diagram, the composite $g\comop f : X \rightarrow Z$
 is implicitly present in the diagram (but generally
not drawn).
\end{itemize}
Since objects and morphisms may appear 
more than once in the diagram, as different vertices
and edges, we will refer to vertices and edges to avoid ambiguity.''
\end{plDefinition}

The informal definition is the only one I've seen which
explicitly acknowledges some of
what is \emph{not} drawn. 
The later formal definition does not,
and is therefore obviously wrong (as a definition of how diagrams
are drawn and used).

\begin{plDefinition}{Diagram (this time for 
real) \textmd{{\citeAuthorYear[Definition 1.4.20]{Perrone:2019:CatTheory}}})}
{}
``Let $C$ be a category, and $I$ be a small category. A diagram in
$C$ of shape $I$ is a functor $I \rightarrow C$.''
\end{plDefinition}

(\citeAuthorYear[p$200/390$]{LawvereSchanuel:2009:ConceptualMath} 
doesn't quite fit, due to vagueness; roughly
map from directed graph to category, 
not specifying structure-preserving.)

Undefined in:
\citeAuthorYear{MacLane:1998:CategoriesWorking2}.
\end{plSection}
%-----------------------------------------------------------------
\begin{plSection}{Commuting Diagram}
\label{sec:Commuting_Diagram}

\begin{plDiagram}
{Commuting version of \cref{diagram:aCompletedDigraph}}
{aCommutingDiagram}
\centering
%\fbox{
\begin{tikzcd}
[
row sep=1.2cm, 
column sep=2.5cm,
ampersand replacement = \&,
execute at begin picture={
     \useasboundingbox (-3.3,-2.5) rectangle (4.25,3.4); }
    ]
V_0
\arrow[loop above, blue, crossing over]
\arrow[dr, "{e_{01}}" ] 
\arrow[drr, "e_{12} \comop e_{01}"', "e_{02}"  {near start},
bend left]
\arrow[ddr, "e_{13} \comop e_{01}", "e_{03}"' {near start},
bend right]
\& 
\& 
\\
\&
V_1 
\arrow[loop above, blue,crossing over]
\arrow[r, "e_{12}"] 
\arrow[d, "e_{13}"']
\arrow[dr, "e_{24} \comop e_{12}", "e_{34} \comop e_{13}"',
dashed, red]
\& 
V_2 
\arrow[loop right, crossing over, blue]
\arrow[d, "e_{24}"] 
\\
\& 
V_3 
\arrow[loop below, blue,crossing over]
\arrow[r, "e_{34}"']
\& 
V_4
\arrow[loop right, blue, crossing over]
\arrow[
"e_{24} \comop e_{02}",
"e_{34} \comop e_{03}" {near end},
"e_{24} \comop e_{12} \comop e_{01}" {near start},
"e_{34} \comop e_{13} \comop e_{01}"' {near start},
from=1-1,to=3-3, draw=DarkGreen, dashed, bend left=100,]
\end{tikzcd}
%}
\end{plDiagram}

In \cref{diagram:aCompletedDigraph}, 
any of the pair of edges with the same head and tail might be
taken to be the same edge, and still satisfy the definition of a
category. 
If all such ``redundant'' pairs are reduced to single edges,
then the diagram is said to \ding{commute}.
This is shown in \cref{diagram:aCommutingDiagram}

Commutative diagrams are in some sense the heart of category
theory,
but both ``commutative'' and ``diagram'' are problematic.

I have been unable to find an explanation for the use of
the word ``commute'' to mean ``all displayed paths
with the same head and tail are equivalent''.
This is one of the early symptoms that there's something wrong:
The fact that a key term is used for, as far as I can tell, 
an unrelated concept
from closely related areas of mathematics (eg commutative groups)
is at best, evidence of flawed exposition, if not confused thinking.
To use ``commute'' in the context of the binary \compose
operation to mean anything other than $e_0 \comop e_1 = e_1 \comop e_0$
adds pointlessly to the cognitive load of someone new to the subject.

The convention in category theory is to leave out identity loops
and composition edges when drawing diagrams,
which is a symptom that perhaps the identities and compositions
ought not be there.

It worth noting that ``diagram'' is rarely defined in introductory
texts, at least, 
not until long after diagrams have been in use.
And the standard definition---functor from indexing category
to ambient category
(eg \cite[][Definition 1.6.4]{Riehl:2017:CatTheory})---doesn't reflect how
diagrams are actually drawn and used.

What's drawn is a subgraph, not a category (unless we use
a path-equivalence/identity-free definition of categories).
The functor is essentially irrelevant.
The displayed subgraph is a device for 
reducing the cognitive burden of certain (mental) computations
(like a chess board and pieces);
what's drawn is (should be) the minimum necessary 
to get to the desired result.~\cite{DutilhNovaes:2012:FormalLanguages}

(\textbf{Question:} is diagram chasing the same thing as proving
a diagram commutes?)
\end{plSection}

%-----------------------------------------------------------------
\begin{plSection}{Monic, epic, isic (Monepisic?) edges}
\label{sec:monic_epic_isic}

Two edges are \ding[parallel edges]{parallel} 
if they have the same head and tail.
Same for paths.

\begin{plSection}{Category}

See, for example, \cite{Perrone:2019:CatTheory}.

\begin{plDiagram}
{Monic edge $e$: 
$\left( f \neq g \right) 
\implies 
\left( e \comop f \, \neq \, e \comop g \right)$.}
{monic}
\centering
\begin{tikzcd}
V_0 
\arrow[r, bend left, "f"]
\arrow[r, bend right, swap, "g"]
& V_1 
\arrow[r, "e"]
& V_2 
\end{tikzcd}
\end{plDiagram}

An edge $e$ is \ding{monic} (aka a monomorphism, left-cancelable)
if, for any matching parallel edges $f,g$:
\begin{align*}
\left( e \comop f = e \comop g \right) 
& 
\implies 
\left( f = g \right) 
\\
\left( f \neq g \right) 
&
\implies 
\left( e \comop f \neq e \comop g \right) 
\end{align*}

\begin{plDiagram}
{Epic edge $e$: 
$\left( f \neq g \right)
 \implies 
 \left( f \comop e \, \neq \, g \comop e \right)$.}
{epic}
\centering
\begin{tikzcd}
V_0 \arrow[r, "e"]
& V_1 
\arrow[r, bend left, "f"]
\arrow[r, bend right, "g"']
& V_2 
\end{tikzcd}
\end{plDiagram}

An edge $e$ is \ding{epic} (aka epimorphism, right-cancelable)
if, for any matching parallel edges $f,g$:
\begin{align*}
\left( f \comop e = g \comop e \right) 
& 
\implies 
\left( f = g \right)
\\
\left( f \neq g \right)
& 
\implies 
\left( f \comop e \neq g \comop e \right) 
\end{align*}
(\textbf{Question:} 
what is an edge/path that is both epic and monic?
Clumsy ``epic-monic'' may be only option.)

First duality: reverse all edges gives monic $\,\leftrightarrow\,$ epic.

\begin{plDiagram}
{Split monic edge $e$, if the two edge path
$V_0 \longrightarrow V_0$
composes to the identity loop.}
{splitMonic}
\centering
\begin{tikzcd}
V_0 
\arrow[loop left, blue, "I_{V_0}"]
\arrow[r, "e", bend left]
\arrow[r, "e^{-left}"', leftarrow, bend right]
& 
V_1 
\end{tikzcd}
\end{plDiagram}

An edge $e$ is \ding{split monic} (aka has a left inverse)
if there exists an $e^{-\text{left}}$, the \ding{retraction},
such that
\[
e^{-\text{left}} \comop e = \identity(\tail(e))
\]
Every split monic edge is monic.

\begin{plDiagram}
{Split epic edge $e$, if the two edge path
$V_1 \longrightarrow V_1$
composes to the identity loop.}
{splitEpic}
\centering
\begin{tikzcd}
V_0 
\arrow[r, "e", bend left]
\arrow[r, "e^{-right}"', leftarrow, bend right]
& 
V_1 
\arrow[loop right, blue, "I_{V_1}"]
\end{tikzcd}
\end{plDiagram}

An edge $e$ is \ding{split epic} (aka has a right inverse)
if there exists an $e^{-\text{right}}$, the \ding{splitting}, 
such that
\[
e \comop e^{-\text{right}} = \identity(\head(e))
\]
Every split epic edge is epic.

\begin{plDiagram}
{Isic edge $e$, if both paths $V_0 \longrightarrow V_0$
are equivalent (compose to the identity loop) and the 
same for both paths $V_1 \longrightarrow V_1$.}
{isic}
\centering
\begin{tikzcd}
V_0 
\arrow[loop left, blue, "I_{V_0}"]
\arrow[r, "e", bend left]
\arrow[r, "e^{-1}"', leftarrow, bend right]
& 
V_1 
\arrow[loop right, blue, "I_{V_1}"]
\end{tikzcd}
\end{plDiagram}

An edge $e$ is \ding{isic} (aka an isomorphism, invertible)
if there exists an edge $e^{-1}$ such that
\[
e^{-1} \comop e = \identity(\tail(e))
\]
and
\[
e \comop e^{-1} = \identity(\head(e))
\]
$e$ is isic \liff it is both split monic and split epic.\\
Proof (belabored, probably unnecessary).
We need to show that $e^{-\text{left}} = e^{-\text{right}}$:
\begin{align*}
e \comop e^{-\text{right}} 
& = 
\identity(\head(e)) 
\\
e^{-\text{left}} \comop \left( e \comop e^{-\text{right}} \right)
& = 
e^{-\text{left}} \comop \identity(\head(e)) 
\\
\left( e^{-\text{left}} \comop e \right) \comop e^{-\text{right}} 
& = 
e^{-\text{left}}
\\
\identity(\head(e)) \comop e^{-\text{right}} 
& = 
e^{-\text{left}} 
\\
e^{-\text{right}} 
& = 
e^{-\text{left}} 
\end{align*}
(Note that this seems much simpler in left/right invertible language.)

(\textbf{Note:} in a topos monic$\,\wedge\,$epic $\implies$ isic.
Is that because all monic/epic are split?)

(\textbf{TODO:} describe these ideas in the context of
structures and structure-preserving functions vs
set and all functions, to distinguish epic/monic from split versions.
eg non-surjective epimorphisms, non-injective monomorphism.)

Monic, epic, and isic are ``abstracted'' 
from one-to-one, onto, and invertible functions.
At this point, it is, at best, not clear that we have gained
anything and we definitely have lost something.
I put quotes around ``abstracted'' because the new concepts are
not simplifications of the originals.
First of all, 
we've broken the modularity of the original concepts:
one-to-one, onto, and invertible can be determined from
the function alone, and the fact that the domain and codomain
somewhat slippery can be handled directly.
(\textbf{TODO:} find the right way to say this.)
Monic, epic, and, particularly, isic depend other edges in the category, 
and details of how \compose is defined.
Specifically, note that,
a function that is one-to-one and onto is
therefore invertible, and vice versa.
On the other hand, all isic edges are both monic and epic,
but an edge that is both monic and epic need not be isic.
For an edge to be isic, it requires the existence of an ``inverse''
edge, that cancels when composed with the original edge 
in either order.

Difference between split monic/epic and simple monic/epic
is that inverse edges need not exist in simple case.
In a general sets-and-functions context, split and simple versions
are the same.
In a structures-and-structure-preserving-functions context,
this is no longer true, because, although the inverse functions
will exist, they may not be structure-preserving.
Is this any clearer in category language vs sets-and-functions?
I don't think so.
\end{plSection}
%-----------------------------------------------------------------
\begin{plSection}{Misleading (?) diagrams}

Standard definitions refer to pairs of edges $f, g$,
which may lead the less careful to unconsciously assume
the condition is defined as 
``there exists some pair $f,g$ such that \ldots'',
rather than
``for all such pairs $f,g$ \ldots''.

A realistic diagram of the monic case 
is in \cref{diagram:monicDiagram}.
Even this is idealized, since common categories (eg Sets)
would have an uncountable number of such edges.

\begin{plDiagram}
{More realistic monic diagram.}
{monicDiagram}
\centering
\begin{tikzcd}
V_0 
\arrow[r, bend left=90, "f_0"]
\arrow[r, bend left=30, "f_1","{\vdots}"' inner sep=0.0ex]
%\arrow[r, bend right=30, swap, "f_{n-1}"]
%\arrow[r, bend right=100, swap, "f_{n}"]
& V_1 
\arrow[r, "e"]
& V_2 
\arrow["e \comop f_0",
from=1-1,to=1-3, red, dashed, bend right=30,]
\arrow["e \comop f_1",
from=1-1,to=1-3, red, dashed, bend right=60,
"{\vdots}"' inner sep=0.0ex]
\end{tikzcd}
\end{plDiagram}

An edge $e$ i \ding{monic} (aka a monomorphism, left-cancelable)
if, for any matching parallel edges $f_i,f_j$:
\begin{align*}
\left( e \comop f_i = e \comop f_j \right) 
& 
\implies 
\left( f_i = f_j \right) 
\\
\left( f_i \neq f_j \right) 
&
\implies 
\left( e \comop f_i \neq e \comop f_j \right) 
\end{align*}
\end{plSection}%{Misleading (?) diagrams}
%-----------------------------------------------------------------
\end{plSection}%{Bottom up}
%-----------------------------------------------------------------
\end{plSection}%{Category and Topos}
%-----------------------------------------------------------------
%-----------------------------------------------------------------
